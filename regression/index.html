
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Regression and time-series prediction &#8212; Julia for High-Performance Scientific Computing</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx_lesson.css?v=e9df6548" />
    <link rel="stylesheet" type="text/css" href="../_static/term_role_formatting.css?v=4194e21c" />
    <link rel="stylesheet" type="text/css" href="../_static/overrides.css" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=55b5f74b"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/minipres.js?v=a0d29692"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'regression';</script>
    <script data-domain="enccs.github.io/julia-for-hpda" defer="defer" src="https://plausible.io/js/script.js"></script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex/" />
    <link rel="search" title="Search" href="../search/" />
    <link rel="next" title="Instructor’s guide" href="../guide/" />
    <link rel="prev" title="Data science and machine learning" href="../data-science/" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search/"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/ENCCS.jpg" class="logo__image only-light" alt="Julia for High-Performance Scientific Computing - Home"/>
    <img src="../_static/ENCCS.jpg" class="logo__image only-dark pst-js-only" alt="Julia for High-Performance Scientific Computing - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Prerequisites</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../setup/">Installing packages</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">The lesson</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../motivation/">Motivation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dataformats-dataframes/">Data Formats and Dataframes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../linear-algebra/">Linear algebra</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sciml/">Scientific Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data-science/">Data science and machine learning</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Regression and time-series prediction</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../guide/">Instructor’s guide</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/regression.rst" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.rst</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Regression and time-series prediction</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-with-synthetic-data">Linear regression with synthetic data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-models-with-basis-functions">Linear models with basis functions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fitting-a-polynomial-to-data">Fitting a polynomial to data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-data">Loading data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#non-linear-regression">Non-linear regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#climate-data">Climate data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#airfoil-data-set">Airfoil data set</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-regression-example">Simple regression example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Exercises</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#some-fourier-based-models-extra-material">Some Fourier based models (extra material)</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="regression-and-time-series-prediction">
<span id="regression"></span><h1>Regression and time-series prediction<a class="headerlink" href="#regression-and-time-series-prediction" title="Link to this heading">#</a></h1>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>How can I perform simple linear regression in Julia?</p></li>
<li><p>How to do linear regression with non-linear basis functions?</p></li>
<li><p>How do to basic Fourier based regression?</p></li>
<li><p>How to perform non-linear regression and time-series prediction?</p></li>
</ul>
</div>
<div class="admonition-instructor-note instructor-note admonition" id="instructor-note-0">
<p class="admonition-title">Instructor note</p>
<ul class="simple">
<li><p>90 min teaching</p></li>
<li><p>60 min exercises</p></li>
</ul>
</div>
<div class="admonition-callout callout admonition" id="callout-0">
<p class="admonition-title">Callout</p>
<p>The code in this lession is written for Julia v1.11.3.</p>
</div>
<section id="linear-regression-with-synthetic-data">
<h2>Linear regression with synthetic data<a class="headerlink" href="#linear-regression-with-synthetic-data" title="Link to this heading">#</a></h2>
<p>We begin with some simple examples of linear regression on generated data.
For the models we will use the package GLM (Generlized Linear Models),
which among other things contains linear regression models.</p>
<p>Let’s start by generating some data along a line and add normally distributed noise.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Plots</span><span class="p">,</span><span class="w"> </span><span class="n">GLM</span><span class="p">,</span><span class="w"> </span><span class="n">DataFrames</span>

<span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">Vector</span><span class="p">(</span><span class="n">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="o">=</span><span class="mi">20</span><span class="p">))</span>
<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="o">*</span><span class="n">X</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="mf">3.4</span>
<span class="n">y_noisy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nd">@.</span><span class="w"> </span><span class="mi">5</span><span class="o">*</span><span class="n">X</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">3.4</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">randn</span><span class="p">()</span>

<span class="n">plt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;linear&quot;</span><span class="p">)</span>
<span class="n">plot!</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y_noisy</span><span class="p">,</span><span class="w"> </span><span class="n">seriestype</span><span class="o">=</span><span class="ss">:scatter</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;data&quot;</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-center">
<img alt="../_images/linear_synth_1.png" src="../_images/linear_synth_1.png" />
</figure>
<p>Given data <span class="math notranslate nohighlight">\(x_1,x_2,\ldots,x_k\)</span> and responses <span class="math notranslate nohighlight">\(y_1,y_2,\ldots,y_k\)</span>, the ordinary least squares method
finds the linear function <span class="math notranslate nohighlight">\(l(x) = ax+b\)</span> minimizing the sum of squares error <span class="math notranslate nohighlight">\(\sum_i (l(x_i)-y_i)^2\)</span>.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Plots</span><span class="p">,</span><span class="w"> </span><span class="n">GLM</span><span class="p">,</span><span class="w"> </span><span class="n">DataFrames</span>

<span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">Vector</span><span class="p">(</span><span class="n">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="o">=</span><span class="mi">20</span><span class="p">))</span>
<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="o">*</span><span class="n">X</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="mf">3.4</span>
<span class="n">y_noisy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nd">@.</span><span class="w"> </span><span class="mi">5</span><span class="o">*</span><span class="n">X</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">3.4</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">randn</span><span class="p">()</span>

<span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cX</span><span class="o">=</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">cy</span><span class="o">=</span><span class="n">y_noisy</span><span class="p">)</span>
<span class="n">lm1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fit</span><span class="p">(</span><span class="n">LinearModel</span><span class="p">,</span><span class="w"> </span><span class="nd">@formula</span><span class="p">(</span><span class="n">cy</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">cX</span><span class="p">),</span><span class="w"> </span><span class="n">df</span><span class="p">)</span>

<span class="c"># the above is the same as @formula(cy ~ cX + 1), which also works</span>

<span class="c"># alternative syntax</span>
<span class="c"># lm(@formula(cy ~ cX), df)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}, Vector{Int64}}}}, Matrix{Float64}}

cy ~ 1 + cX # the constant term (intercept) is there, same as if we do @formula(cy ~ cX + 1)

Coefficients:
───────────────────────────────────────────────────────────────────────
               Coef.  Std. Error      t  Pr(&gt;|t|)  Lower 95%  Upper 95%
───────────────────────────────────────────────────────────────────────
Intercept)  3.46467   0.448322    7.73    &lt;1e-06    2.52278    4.40656
cX          5.05127   0.0766497  65.90    &lt;1e-22    4.89024    5.21231
───────────────────────────────────────────────────────────────────────
</pre></div>
</div>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># note the order in the formula argument</span>
<span class="n">fit</span><span class="p">(</span><span class="n">LinearModel</span><span class="p">,</span><span class="w"> </span><span class="nd">@formula</span><span class="p">(</span><span class="n">cX</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">cy</span><span class="p">),</span><span class="w"> </span><span class="n">df</span><span class="p">)</span><span class="w"> </span><span class="c"># this would model line with slope 1/5 and intercept -3.4/5</span>
</pre></div>
</div>
<p>Now let’s plot the resulting prediction (green) together with the underlying line (blue) and data points.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Plots</span><span class="p">,</span><span class="w"> </span><span class="n">GLM</span><span class="p">,</span><span class="w"> </span><span class="n">DataFrames</span>

<span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">Vector</span><span class="p">(</span><span class="n">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="o">=</span><span class="mi">20</span><span class="p">))</span>
<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">5</span><span class="o">*</span><span class="n">X</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="mf">3.4</span>
<span class="n">y_noisy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nd">@.</span><span class="w"> </span><span class="mi">5</span><span class="o">*</span><span class="n">X</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">3.4</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">randn</span><span class="p">()</span>

<span class="n">plt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;linear&quot;</span><span class="p">)</span>
<span class="n">plot!</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y_noisy</span><span class="p">,</span><span class="w"> </span><span class="n">seriestype</span><span class="o">=</span><span class="ss">:scatter</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;data&quot;</span><span class="p">)</span>

<span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cX</span><span class="o">=</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">cy</span><span class="o">=</span><span class="n">y_noisy</span><span class="p">)</span>
<span class="n">lm1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fit</span><span class="p">(</span><span class="n">LinearModel</span><span class="p">,</span><span class="w"> </span><span class="nd">@formula</span><span class="p">(</span><span class="n">cy</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">cX</span><span class="p">),</span><span class="w"> </span><span class="n">df</span><span class="p">)</span>

<span class="n">y_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GLM</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">lm1</span><span class="p">)</span>

<span class="c"># alternative: do it explicitly</span>
<span class="c"># coeffs = coeftable(lm1).cols[1] # intercept and slope</span>
<span class="c"># y_pred = coeffs[1] .+ coeffs[2]*X</span>

<span class="n">plot!</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;predicted&quot;</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>

<span class="n">lm1</span>
</pre></div>
</div>
<figure class="align-center" id="id15">
<img alt="../_images/linear_synth_2.png" src="../_images/linear_synth_2.png" />
<figcaption>
<p><span class="caption-text">Image of linear model prediction. The example shown has intercept 2.9 and slope 5.1 (the result depends on random added noise).</span><a class="headerlink" href="#id15" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Multivariate linear models are done in a similar way. Now we are fitting a nultivariate linear function that minizes the sum of
squares error. In the following example we generate a linear function of 4 variables with random coefficients (normally distributed).
On top of that we add normally distributed noise.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Plots</span><span class="p">,</span><span class="w"> </span><span class="n">GLM</span><span class="p">,</span><span class="w"> </span><span class="n">DataFrames</span>

<span class="n">n</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">4</span>
<span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rand</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="n">n</span><span class="p">)</span>

<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">X</span><span class="o">*</span><span class="n">C</span><span class="p">[</span><span class="mi">2</span><span class="o">:</span><span class="k">end</span><span class="p">]</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="n">C</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y_noisy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="mf">0.01</span><span class="o">*</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cX1</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="n">cX2</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="n">cX3</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="n">cX4</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span><span class="w"> </span><span class="n">cy</span><span class="o">=</span><span class="n">y_noisy</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">lm2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="nd">@formula</span><span class="p">(</span><span class="n">cy</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">cX1</span><span class="o">+</span><span class="n">cX2</span><span class="o">+</span><span class="n">cX3</span><span class="o">+</span><span class="n">cX4</span><span class="p">),</span><span class="w"> </span><span class="n">df</span><span class="p">)</span>

<span class="n">println</span><span class="p">(</span><span class="n">lm2</span><span class="p">)</span>
<span class="n">println</span><span class="p">()</span>
<span class="n">println</span><span class="p">(</span><span class="s">&quot;Coefficient vector:&quot;</span><span class="p">)</span>
<span class="n">print</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>cy ~ 1 + cX1 + cX2 + cX3 + cX4

Coefficients:
───────────────────────────────────────────────────────────────────────────
                 Coef.  Std. Error        t  Pr(&gt;|t|)  Lower 95%  Upper 95%
───────────────────────────────────────────────────────────────────────────
(Intercept)  -1.02879   0.0035902   -286.55    &lt;1e-99  -1.03592   -1.02166
cX1          -0.935462  0.0034155   -273.89    &lt;1e-99  -0.942242  -0.928681
cX2           0.183037  0.00345387    52.99    &lt;1e-71   0.17618    0.189894
cX3          -0.737696  0.00390208  -189.05    &lt;1e-99  -0.745443  -0.729949
cX4          -1.59192   0.00327437  -486.18    &lt;1e-99  -1.59842   -1.58542
───────────────────────────────────────────────────────────────────────────

[-1.022984643687018; -0.9366244594383493; 0.18095529608948402; -0.7396860440808664; -1.595858344253308;;]
</pre></div>
</div>
</section>
<section id="linear-models-with-basis-functions">
<h2>Linear models with basis functions<a class="headerlink" href="#linear-models-with-basis-functions" title="Link to this heading">#</a></h2>
<p>Using the package GLM, we can incorporate linear models with basis functions in a convenient way,
that is to model a function as a linear combination of given non-linear functions such polynomials
or trigonometric functions.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Plots</span><span class="p">,</span><span class="w"> </span><span class="n">GLM</span><span class="p">,</span><span class="w"> </span><span class="n">DataFrames</span>

<span class="c"># try this polynomial</span>
<span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">range</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">X</span><span class="o">.^</span><span class="mi">5</span><span class="w"> </span><span class="o">.-</span><span class="w"> </span><span class="mi">34</span><span class="o">*</span><span class="n">X</span><span class="o">.^</span><span class="mi">3</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="mi">225</span><span class="o">*</span><span class="n">X</span>
<span class="n">y_noisy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="n">randn</span><span class="p">(</span><span class="mi">40</span><span class="p">,)</span>

<span class="n">plt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;polynomial&quot;</span><span class="p">)</span>
<span class="n">plot!</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y_noisy</span><span class="p">,</span><span class="w"> </span><span class="n">seriestype</span><span class="o">=</span><span class="ss">:scatter</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;data&quot;</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-center" id="id16">
<img alt="../_images/linear_basis_1.png" src="../_images/linear_basis_1.png" />
<figcaption>
<p><span class="caption-text">A polynomial function with noisy data.</span><a class="headerlink" href="#id16" title="Link to this image">#</a></p>
</figcaption>
</figure>
<section id="fitting-a-polynomial-to-data">
<h3>Fitting a polynomial to data<a class="headerlink" href="#fitting-a-polynomial-to-data" title="Link to this heading">#</a></h3>
<p>Fitting a linear model with basis functions means that we try to approximate our function with for example a polynomial
<span class="math notranslate nohighlight">\(p(x)=ax^5+bx^4+cx^3+dx^2+ex+f\)</span>. We fit this model to the data in a least squares sense, which works since the model
is linear in the coefficients <span class="math notranslate nohighlight">\(a,b,c,d,e,f\)</span>, even though non-linear in the data <span class="math notranslate nohighlight">\(x\)</span>. The degree of the polynomial needed
to get a good fit is not known in advance but for this illustration we pick the same degree (5) as when generating the data.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Plots</span><span class="p">,</span><span class="w"> </span><span class="n">GLM</span><span class="p">,</span><span class="w"> </span><span class="n">DataFrames</span>

<span class="c"># try this polynomial</span>
<span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">range</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">X</span><span class="o">.^</span><span class="mi">5</span><span class="w"> </span><span class="o">.-</span><span class="w"> </span><span class="mi">34</span><span class="o">*</span><span class="n">X</span><span class="o">.^</span><span class="mi">3</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="mi">225</span><span class="o">*</span><span class="n">X</span>
<span class="n">y_noisy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="n">randn</span><span class="p">(</span><span class="mi">40</span><span class="p">,)</span>

<span class="n">plt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;polynomial&quot;</span><span class="p">)</span>
<span class="n">plot!</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y_noisy</span><span class="p">,</span><span class="w"> </span><span class="n">seriestype</span><span class="o">=</span><span class="ss">:scatter</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;data&quot;</span><span class="p">)</span>

<span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cX</span><span class="o">=</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">cy</span><span class="o">=</span><span class="n">y_noisy</span><span class="p">)</span>

<span class="n">lm3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="nd">@formula</span><span class="p">(</span><span class="n">cy</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">cX</span><span class="o">^</span><span class="mi">5</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cX</span><span class="o">^</span><span class="mi">4</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cX</span><span class="o">^</span><span class="mi">3</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cX</span><span class="o">^</span><span class="mi">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cX</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">),</span><span class="w"> </span><span class="n">df</span><span class="p">)</span>

<span class="n">y_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GLM</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">lm3</span><span class="p">)</span>

<span class="n">plot!</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;predicted&quot;</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>

<span class="n">lm3</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}, Vector{Int64}}}}, Matrix{Float64}}

cy ~ 1 + :(cX ^ 5) + :(cX ^ 4) + :(cX ^ 3) + :(cX ^ 2) + cX

Coefficients:
───────────────────────────────────────────────────────────────────────────────────────
                     Coef.   Std. Error         t  Pr(&gt;|t|)     Lower 95%     Upper 95%
───────────────────────────────────────────────────────────────────────────────────────
(Intercept)   -0.0354375    0.343821        -0.10    0.9185   -0.734166      0.663291
cX ^ 5         1.00118      0.000551333   1815.92    &lt;1e-85    1.00006       1.0023
cX ^ 4        -0.000992084  0.00169158      -0.59    0.5614   -0.00442979    0.00244563
cX ^ 3       -34.054        0.0236797    -1438.11    &lt;1e-82  -34.1021      -34.0058
cX ^ 2         0.0230557    0.0571179        0.40    0.6890   -0.0930219     0.139133
cX           225.511        0.226822       994.22    &lt;1e-76  225.05        225.972
───────────────────────────────────────────────────────────────────────────────────────
</pre></div>
</div>
<figure class="align-center" id="id17">
<img alt="../_images/linear_basis_1_pred.png" src="../_images/linear_basis_1_pred.png" />
<figcaption>
<p><span class="caption-text">Fitting a polynomial to data.</span><a class="headerlink" href="#id17" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>
<section id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">#</a></h2>
<p>Let us illustrate linear regression on real data sets. The first dataset comes from the RDatasets package
and are data from chemical experiments for the production of formeldyhyde.
The data columns are ammount of Carbohydrate (ml) and Optical Density of a purple color on a spectrophotometer.</p>
<p>Sources:</p>
<ul class="simple">
<li><p>Bennett, N. A. and N. L. Franklin (1954), Statistical Analysis in Chemistry and the Chemical Industry, New York: Wiley.</p></li>
<li><p>McNeil, D. R. (1977), Interactive Data Analysis, New York: Wiley.</p></li>
</ul>
<div class="admonition-todo admonition" id="id1">
<p class="admonition-title">Todo</p>
<p>In the exerises below we use the packages GLM, RDatasets, Plots and DataFrames:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Pkg</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;GLM&quot;</span><span class="p">)</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;RDatasets&quot;</span><span class="p">)</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;Plots&quot;</span><span class="p">)</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;DataFrames&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition-todo admonition" id="id2">
<p class="admonition-title">Todo</p>
<p>Formaldehyde example</p>
<p>To load the dataset, you can do:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">GLM</span><span class="p">,</span><span class="w"> </span><span class="n">RDatasets</span><span class="p">,</span><span class="w"> </span><span class="n">Plots</span>
<span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dataset</span><span class="p">(</span><span class="s">&quot;datasets&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Formaldehyde&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The columns of the dataframe are called <cite>Carb</cite> and <cite>OptDen</cite> for the ammount of Carbohydrate and Optical Density.
You can plot the data as follows:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Carb</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="o">.</span><span class="n">OptDen</span><span class="p">,</span><span class="w"> </span><span class="n">seriestype</span><span class="o">=</span><span class="ss">:scatter</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;formaldehyde data&quot;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>
</pre></div>
</div>
<p>To model Density as a linear function of Carbohydrate you can do as follows.
The <cite>predict</cite> method is used to make model predictions.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fit</span><span class="p">(</span><span class="n">LinearModel</span><span class="p">,</span><span class="w"> </span><span class="nd">@formula</span><span class="p">(</span><span class="n">OptDen</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Carb</span><span class="p">),</span><span class="w"> </span><span class="n">df</span><span class="p">)</span>
<span class="n">y_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GLM</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<p>To add the prediction to the plot and print the model results you can do:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">plot!</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Carb</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;model&quot;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>
<span class="n">model</span>
</pre></div>
</div>
<div class="admonition-a-suggestion solution important dropdown admonition" id="solution-0">
<p class="admonition-title">A suggestion</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">GLM</span><span class="p">,</span><span class="w"> </span><span class="n">RDatasets</span><span class="p">,</span><span class="w"> </span><span class="n">Plots</span>

<span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dataset</span><span class="p">(</span><span class="s">&quot;datasets&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Formaldehyde&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Carb</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="o">.</span><span class="n">OptDen</span><span class="p">,</span><span class="w"> </span><span class="n">seriestype</span><span class="o">=</span><span class="ss">:scatter</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;formaldehyde data&quot;</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>

<span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fit</span><span class="p">(</span><span class="n">LinearModel</span><span class="p">,</span><span class="w"> </span><span class="nd">@formula</span><span class="p">(</span><span class="n">OptDen</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Carb</span><span class="p">),</span><span class="w"> </span><span class="n">df</span><span class="p">)</span>

<span class="n">y_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GLM</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="n">plot!</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">Carb</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;model&quot;</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>

<span class="n">model</span>
</pre></div>
</div>
<figure class="align-center">
<img alt="../_images/linear_formaldehyde.png" src="../_images/linear_formaldehyde.png" />
</figure>
</div>
</div>
<div class="admonition-todo admonition" id="id3">
<p class="admonition-title">Todo</p>
<p>Changing hyperparameters</p>
<p>Take a look at the code in example <a class="reference internal" href="#fitting-a-polynomial-to-data">Fitting a polynomial to data</a>.
This fit is pretty tight.</p>
<ul class="simple">
<li><p>What happens if you increase the noise by say 100 times?</p></li>
<li><p>What happens if if you use a degree 6 or 7 polynomial to fit the data instead?</p></li>
</ul>
<p>You can try the second experiment with the original noise level.</p>
<div class="admonition-solution solution important dropdown admonition" id="solution-1">
<p class="admonition-title">Solution</p>
<p>You can change the following rows:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># y_noisy = y .+ randn(40,)</span>
<span class="n">y_noisy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="mi">100</span><span class="o">*</span><span class="n">randn</span><span class="p">(</span><span class="mi">40</span><span class="p">,)</span>

<span class="c"># lm3 = lm(@formula(cy ~ cX^5 + cX^4 + cX^3 + cX^2 + cX + 1), df)</span>
<span class="n">lm3</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="nd">@formula</span><span class="p">(</span><span class="n">cy</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">cX</span><span class="o">^</span><span class="mi">7</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cX</span><span class="o">^</span><span class="mi">6</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cX</span><span class="o">^</span><span class="mi">5</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cX</span><span class="o">^</span><span class="mi">4</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cX</span><span class="o">^</span><span class="mi">3</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cX</span><span class="o">^</span><span class="mi">2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cX</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">),</span><span class="w"> </span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let us have a look at linear regression on real multidimensional data. For this we will use comes from the Rdatasets
package and the “trees” dataset, which consists of measurements on
black cherry trees: girth, height and volume
(see Atkinson, A. C. (1985) Plots, Transformations and Regression. Oxford University Press).</p>
<div class="admonition-todo admonition" id="id4">
<p class="admonition-title">Todo</p>
<p>Black cherry trees</p>
<p>In this exerise we use also the package StatsBase:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Pkg</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;StatsBase&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Load the trees data set as follows:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">GLM</span><span class="p">,</span><span class="w"> </span><span class="n">RDatasets</span><span class="p">,</span><span class="w"> </span><span class="n">StatsBase</span><span class="p">,</span><span class="w"> </span><span class="n">Plots</span>
<span class="c"># Girth Height and Volume of Black Cherry Trees</span>
<span class="n">trees</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dataset</span><span class="p">(</span><span class="s">&quot;datasets&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;trees&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">trees</span>
</pre></div>
</div>
<p>Randomly split the data set into a training and testing data set.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">n_rows</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">size</span><span class="p">(</span><span class="n">df</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">rows_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="mi">1</span><span class="o">:</span><span class="n">n_rows</span><span class="p">,</span><span class="w"> </span><span class="kt">Int</span><span class="p">(</span><span class="n">round</span><span class="p">(</span><span class="n">n_rows</span><span class="o">*</span><span class="mf">0.8</span><span class="p">)),</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span>
<span class="n">rows_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="n">n_rows</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="o">~</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">rows_train</span><span class="p">)]</span>

<span class="n">L_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="n">rows_train</span><span class="p">,</span><span class="o">:</span><span class="p">]</span>
<span class="n">L_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="n">rows_test</span><span class="p">,</span><span class="o">:</span><span class="p">]</span>
</pre></div>
</div>
<p>It is reasonable to try to fit the logarithm of volume as a linear function of
the logarithm of the height and logarithm of the girth. This is because the
volume is presumably proportional to the height times the girth squared.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># reasonable to look at logarithms since we can expect something like V~h*g^2 and</span>
<span class="c"># log V = constant + log h + 2log g</span>
<span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fit</span><span class="p">(</span><span class="n">LinearModel</span><span class="p">,</span><span class="w"> </span><span class="nd">@formula</span><span class="p">(</span><span class="n">log</span><span class="p">(</span><span class="n">Volume</span><span class="p">)</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">log</span><span class="p">(</span><span class="n">Girth</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">log</span><span class="p">(</span><span class="n">Height</span><span class="p">)),</span><span class="w"> </span><span class="n">L_train</span><span class="p">)</span>
</pre></div>
</div>
<p>Lastly, make predictions on the training set according to the model and compute the
root mean squared error of the prediction (for instance on the training set).</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">Z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">L_train</span>
<span class="n">y_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GLM</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">Z</span><span class="p">)</span>

<span class="c"># Root Mean Squared Error</span>
<span class="n">rmse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sqrt</span><span class="p">(</span><span class="n">sum</span><span class="p">((</span><span class="n">exp</span><span class="o">.</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">Z</span><span class="o">.</span><span class="n">Volume</span><span class="p">)</span><span class="o">.^</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">size</span><span class="p">(</span><span class="n">Z</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<div class="admonition-the-whole-script solution important dropdown admonition" id="solution-2">
<p class="admonition-title">The whole script</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">GLM</span><span class="p">,</span><span class="w"> </span><span class="n">RDatasets</span><span class="p">,</span><span class="w"> </span><span class="n">StatsBase</span><span class="p">,</span><span class="w"> </span><span class="n">Plots</span>
<span class="c"># Girth Height and Volume of Black Cherry Trees</span>
<span class="n">trees</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">dataset</span><span class="p">(</span><span class="s">&quot;datasets&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;trees&quot;</span><span class="p">)</span>
<span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">trees</span>

<span class="n">n_rows</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">size</span><span class="p">(</span><span class="n">df</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">rows_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sample</span><span class="p">(</span><span class="mi">1</span><span class="o">:</span><span class="n">n_rows</span><span class="p">,</span><span class="w"> </span><span class="kt">Int</span><span class="p">(</span><span class="n">round</span><span class="p">(</span><span class="n">n_rows</span><span class="o">*</span><span class="mf">0.8</span><span class="p">)),</span><span class="w"> </span><span class="n">replace</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span>
<span class="n">rows_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="n">n_rows</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="o">~</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">rows_train</span><span class="p">)]</span>

<span class="n">L_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="n">rows_train</span><span class="p">,</span><span class="o">:</span><span class="p">]</span>
<span class="n">L_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="n">rows_test</span><span class="p">,</span><span class="o">:</span><span class="p">]</span>

<span class="c"># reasonable to look at logarithms since can expect something like V~h*r^2 and</span>
<span class="c"># log V = constant + log h + 2log r</span>
<span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fit</span><span class="p">(</span><span class="n">LinearModel</span><span class="p">,</span><span class="w"> </span><span class="nd">@formula</span><span class="p">(</span><span class="n">log</span><span class="p">(</span><span class="n">Volume</span><span class="p">)</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">log</span><span class="p">(</span><span class="n">Girth</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">log</span><span class="p">(</span><span class="n">Height</span><span class="p">)),</span><span class="w"> </span><span class="n">L_train</span><span class="p">)</span>

<span class="n">Z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">L_train</span>
<span class="n">y_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GLM</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">Z</span><span class="p">)</span>

<span class="c"># Root Mean Squared Error</span>
<span class="n">rmse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sqrt</span><span class="p">(</span><span class="n">sum</span><span class="p">((</span><span class="n">exp</span><span class="o">.</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">Z</span><span class="o">.</span><span class="n">Volume</span><span class="p">)</span><span class="o">.^</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">size</span><span class="p">(</span><span class="n">Z</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">println</span><span class="p">(</span><span class="n">rmse</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>2.2631848027992776 # rmse

31×3 DataFrame
 Row │ Girth    Height  Volume
     │ Float64  Int64   Float64
─────┼──────────────────────────
   1 │     8.3      70     10.3
   2 │     8.6      65     10.3
   3 │     8.8      63     10.2
   4 │    10.5      72     16.4
   5 │    10.7      81     18.8
   6 │    10.8      83     19.7
   7 │    11.0      66     15.6
   8 │    11.0      75     18.2
   9 │    11.1      80     22.6
  10 │    11.2      75     19.9
  11 │    11.3      79     24.2

And so on (31 data points).
</pre></div>
</div>
</div>
</div>
<div class="admonition-todo admonition" id="id5">
<p class="admonition-title">Todo</p>
<p>Trigonometric basis functions</p>
<p>Try a similar example as the polynomial above but with trigonometric functions <span class="math notranslate nohighlight">\(y(x)=cos(x)+cos(2x)\)</span>.
Here is a snippet that generates data for this example:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Plots</span><span class="p">,</span><span class="w"> </span><span class="n">GLM</span><span class="p">,</span><span class="w"> </span><span class="n">DataFrames</span>

<span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">range</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cos</span><span class="o">.</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="n">cos</span><span class="o">.</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">X</span><span class="p">)</span>
<span class="n">y_noisy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="mf">0.1</span><span class="o">*</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,)</span>
</pre></div>
</div>
<p>To make a dataframe out of the data and fit a linear model to it, you can do:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">y_noisy</span><span class="p">)</span>
<span class="n">lm1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="nd">@formula</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cos</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cos</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cos</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cos</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="n">X</span><span class="p">)),</span><span class="w"> </span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition-a-suggestion solution important dropdown admonition" id="solution-3">
<p class="admonition-title">A suggestion.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Plots</span><span class="p">,</span><span class="w"> </span><span class="n">GLM</span><span class="p">,</span><span class="w"> </span><span class="n">DataFrames</span>

<span class="c"># try a cosine combination</span>
<span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">range</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cos</span><span class="o">.</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="n">cos</span><span class="o">.</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">X</span><span class="p">)</span>
<span class="n">y_noisy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="mf">0.1</span><span class="o">*</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,)</span>

<span class="n">plt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;waveform&quot;</span><span class="p">)</span>
<span class="n">plot!</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y_noisy</span><span class="p">,</span><span class="w"> </span><span class="n">seriestype</span><span class="o">=</span><span class="ss">:scatter</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;data&quot;</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>

<span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">y_noisy</span><span class="p">)</span>

<span class="n">lm1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="nd">@formula</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cos</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cos</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cos</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cos</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="n">X</span><span class="p">)),</span><span class="w"> </span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}, Vector{Int64}}}}, Matrix{Float64}}

y ~ 1 + :(cos(X)) + :(cos(2X)) + :(cos(3X)) + :(cos(4X))

Coefficients:
────────────────────────────────────────────────────────────────────────────
                  Coef.  Std. Error      t  Pr(&gt;|t|)    Lower 95%  Upper 95%
────────────────────────────────────────────────────────────────────────────
(Intercept)   0.0130408   0.0108222   1.21    0.2312  -0.00844393  0.0345256
cos(X)        0.981561    0.015653   62.71    &lt;1e-78   0.950486    1.01264
cos(2X)       0.984984    0.0156219  63.05    &lt;1e-78   0.953971    1.016
cos(3X)      -0.0135547   0.015573   -0.87    0.3863  -0.044471    0.0173616
cos(4X)       0.0148532   0.0155105   0.96    0.3407  -0.015939    0.0456454
────────────────────────────────────────────────────────────────────────────
</pre></div>
</div>
<figure class="align-center" id="id18">
<img alt="../_images/linear_basis_2.png" src="../_images/linear_basis_2.png" />
<figcaption>
<p><span class="caption-text">Fitting trigonomtric functions to data.</span><a class="headerlink" href="#id18" title="Link to this image">#</a></p>
</figcaption>
</figure>
</div>
</div>
</section>
<section id="loading-data">
<h2>Loading data<a class="headerlink" href="#loading-data" title="Link to this heading">#</a></h2>
<p>We will now have a look at a climate data set containing daily mean
temperature, humidity, wind speed and mean pressure at a location in
Dehli India over a period of several years. The data set is available
<a class="reference external" href="https://www.kaggle.com/datasets/sumanthvrao/daily-climate-time-series-data/">here</a>.
In the context of the Dehli dataset we have borrowed some elements of Sebastian Callh’s personal
blog post <em>Forecasting the weather with neural ODEs</em> found <a class="reference external" href="https://sebastiancallh.github.io/post/neural-ode-weather-forecast/">here</a>.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">DataFrames</span><span class="p">,</span><span class="w"> </span><span class="n">CSV</span><span class="p">,</span><span class="w"> </span><span class="n">Plots</span><span class="p">,</span><span class="w"> </span><span class="n">Statistics</span>

<span class="c"># data_path = &quot;C:/Users/davidek/julia_kurser/DailyDelhiClimateTrain.csv&quot;</span>
<span class="c"># full path to data files</span>
<span class="c"># uploaded in julia-for-hpda/content/data</span>
<span class="n">df_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CSV</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span><span class="w"> </span><span class="n">DataFrame</span><span class="p">)</span>
<span class="n">df_train</span>

<span class="n">M</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">df_train</span><span class="o">.</span><span class="n">meantemp</span><span class="w"> </span><span class="n">df_train</span><span class="o">.</span><span class="n">humidity</span><span class="w"> </span><span class="n">df_train</span><span class="o">.</span><span class="n">wind_speed</span><span class="w"> </span><span class="n">df_train</span><span class="o">.</span><span class="n">meanpressure</span><span class="p">]</span>
<span class="n">plottitles</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s">&quot;meantemp&quot;</span><span class="w"> </span><span class="s">&quot;humidity&quot;</span><span class="w"> </span><span class="s">&quot;wind_speed&quot;</span><span class="w"> </span><span class="s">&quot;meanpressure&quot;</span><span class="p">]</span>
<span class="n">plotylabels</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">[</span><span class="s">&quot;C°&quot;</span><span class="w"> </span><span class="s">&quot;g/m^3?&quot;</span><span class="w"> </span><span class="s">&quot;km/h?&quot;</span><span class="w"> </span><span class="s">&quot;hPa&quot;</span><span class="p">]</span>
<span class="c"># color=[1 2 3 4] gives default colors</span>
<span class="n">plot</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="mi">4</span><span class="p">],</span><span class="w"> </span><span class="n">legend</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="n">title</span><span class="o">=</span><span class="n">plottitles</span><span class="p">,</span>
<span class="n">xlabel</span><span class="o">=</span><span class="s">&quot;time (days)&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylabel</span><span class="o">=</span><span class="n">plotylabels</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">800</span><span class="p">,</span><span class="mi">800</span><span class="p">))</span>
</pre></div>
</div>
<figure class="align-center" id="id19">
<img alt="../_images/climate_plots_first.png" src="../_images/climate_plots_first.png" />
<figcaption>
<p><span class="caption-text">Plots of measurements.</span><a class="headerlink" href="#id19" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>The mean pressure data field seems to contain some unreasonably large values. Let us filter those out and consider these missing data.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">DataFrames</span><span class="p">,</span><span class="w"> </span><span class="n">CSV</span><span class="p">,</span><span class="w"> </span><span class="n">Plots</span><span class="p">,</span><span class="w"> </span><span class="n">Statistics</span>

<span class="c"># data_path = &quot;C:/Users/davidek/julia_kurser/2025-02/DailyDelhiClimateTrain.csv&quot;</span>
<span class="c"># full path to data files</span>
<span class="c"># uploaded in julia-for-hpda/content/data</span>
<span class="n">df_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CSV</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span><span class="w"> </span><span class="n">DataFrame</span><span class="p">)</span>

<span class="n">M</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">df_train</span><span class="o">.</span><span class="n">meantemp</span><span class="w"> </span><span class="n">df_train</span><span class="o">.</span><span class="n">humidity</span><span class="w"> </span><span class="n">df_train</span><span class="o">.</span><span class="n">wind_speed</span><span class="w"> </span><span class="n">df_train</span><span class="o">.</span><span class="n">meanpressure</span><span class="p">]</span>

<span class="n">plottitles</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s">&quot;meantemp&quot;</span><span class="w"> </span><span class="s">&quot;humidity&quot;</span><span class="w"> </span><span class="s">&quot;wind_speed&quot;</span><span class="w"> </span><span class="s">&quot;meanpressure&quot;</span><span class="p">]</span>
<span class="n">plotylabels</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">[</span><span class="s">&quot;C°&quot;</span><span class="w"> </span><span class="s">&quot;g/m^3?&quot;</span><span class="w"> </span><span class="s">&quot;km/h?&quot;</span><span class="w"> </span><span class="s">&quot;hPa&quot;</span><span class="p">]</span>

<span class="n">df_train</span><span class="p">[</span><span class="n">df_train</span><span class="o">.</span><span class="n">meanpressure</span><span class="w"> </span><span class="o">.&lt;</span><span class="w"> </span><span class="mi">950</span><span class="p">,</span><span class="ss">:meanpressure</span><span class="p">]</span><span class="w"> </span><span class="o">.=</span><span class="w"> </span><span class="nb">NaN</span>
<span class="n">df_train</span><span class="p">[</span><span class="mi">1050</span><span class="w"> </span><span class="o">.&lt;</span><span class="w"> </span><span class="n">df_train</span><span class="o">.</span><span class="n">meanpressure</span><span class="p">,</span><span class="ss">:meanpressure</span><span class="p">]</span><span class="w"> </span><span class="o">.=</span><span class="w"> </span><span class="nb">NaN</span>

<span class="n">M</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">df_train</span><span class="o">.</span><span class="n">meantemp</span><span class="w"> </span><span class="n">df_train</span><span class="o">.</span><span class="n">humidity</span><span class="w"> </span><span class="n">df_train</span><span class="o">.</span><span class="n">wind_speed</span><span class="w"> </span><span class="n">df_train</span><span class="o">.</span><span class="n">meanpressure</span><span class="p">]</span>

<span class="c"># color=[1 2 3 4] gives default colors</span>
<span class="n">plt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">plot</span><span class="p">(</span><span class="n">M</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="mi">4</span><span class="p">],</span><span class="w"> </span><span class="n">legend</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="n">title</span><span class="o">=</span><span class="n">plottitles</span><span class="p">,</span>
<span class="n">xlabel</span><span class="o">=</span><span class="s">&quot;time (days)&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylabel</span><span class="o">=</span><span class="n">plotylabels</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">800</span><span class="p">,</span><span class="mi">800</span><span class="p">))</span>

<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-center" id="id20">
<img alt="../_images/climate_plots_second.png" src="../_images/climate_plots_second.png" />
<figcaption>
<p><span class="caption-text">Plots of cleaned up data.</span><a class="headerlink" href="#id20" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="non-linear-regression">
<h2>Non-linear regression<a class="headerlink" href="#non-linear-regression" title="Link to this heading">#</a></h2>
<p>In this section we will have a look at non-linear regression methods.</p>
<section id="climate-data">
<h3>Climate data<a class="headerlink" href="#climate-data" title="Link to this heading">#</a></h3>
<p>Now we will consider the problem of predicting one of the climate variables from the others, for example
temperature from humidity, wind speed and pressure. In the process we will see how to set up and train a
neural network in Julia using the package Flux.</p>
<p>Background on neural networks can be found here <a class="reference download internal" download="" href="../_downloads/3b38bba36ae393cce99dc8c78015e69f/julia_kurs_notes.pdf"><code class="xref download docutils literal notranslate"><span class="pre">download</span> <span class="pre">slides</span></code></a>.</p>
<div class="admonition-some-terminology-relating-to-neural-networks callout admonition" id="callout-1">
<p class="admonition-title">Some terminology relating to neural networks</p>
<p>Neural networks can be used to approximate non-linear functions. We difine the newtwork as a chain (composition)
of so-called dense layers. The performance of the network on the training data is measured in terms of the loss
function. In our case this is the mean squared error (mse), which is an anaolog of the sum of squares error
used in linear regression. The square root of the mean squared error is called root mean squared error (rmse).
The training of the network is the process of minimizing the loss function. Here, this is done with the
gradient descent method using an optimizer (in this case ADAM). Gradient descent is an iterative method
which repeatedly takes a step in the negative gradient direction of the loss function. Each such iteration
is known as an epoch.</p>
</div>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">DataFrames</span><span class="p">,</span><span class="w"> </span><span class="n">CSV</span><span class="p">,</span><span class="w"> </span><span class="n">Plots</span><span class="p">,</span><span class="w"> </span><span class="n">Statistics</span><span class="p">,</span><span class="w"> </span><span class="n">Dates</span><span class="p">,</span><span class="w"> </span><span class="n">GLM</span><span class="p">,</span><span class="w"> </span><span class="n">Flux</span><span class="p">,</span><span class="w"> </span><span class="n">StatsBase</span>
<span class="k">using</span><span class="w"> </span><span class="n">MLJ</span><span class="o">:</span><span class="w"> </span><span class="n">shuffle</span><span class="p">,</span><span class="w"> </span><span class="n">partition</span>
<span class="k">using</span><span class="w"> </span><span class="n">Flux</span><span class="o">:</span><span class="w"> </span><span class="n">train!</span>

<span class="c"># data_path = &quot;C:/Users/davidek/julia_kurser/2025-02/DailyDelhiClimateTrain.csv&quot;</span>
<span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CSV</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span><span class="w"> </span><span class="n">DataFrame</span><span class="p">)</span>

<span class="c"># clean up data, drop rows</span>
<span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">filter</span><span class="p">(</span><span class="ss">:meanpressure</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="mi">950</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">1050</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="p">)</span>

<span class="n">topredict</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;mean temp&quot;</span>
<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="o">.</span><span class="n">meantemp</span>
<span class="n">mhumid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">humidity</span><span class="p">)</span>
<span class="n">mspeed</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">wind_speed</span><span class="p">)</span>
<span class="n">mpress</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">meanpressure</span><span class="p">)</span>
<span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[(</span><span class="n">df</span><span class="o">.</span><span class="n">humidity</span><span class="w"> </span><span class="o">.-</span><span class="w"> </span><span class="n">mhumid</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">wind_speed</span><span class="w"> </span><span class="o">.-</span><span class="w"> </span><span class="n">mspeed</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">meanpressure</span><span class="w"> </span><span class="o">.-</span><span class="w"> </span><span class="n">mpress</span><span class="p">)]</span>
<span class="c"># X = [(df.humidity .- 50) (df.wind_speed .- 5) (df.meanpressure .- 1000)]</span>

<span class="c"># can convert data to Float32</span>
<span class="c"># aviods Warning and faster training</span>
<span class="c"># X = Matrix{Float32}(X)</span>
<span class="c"># y = Vector{Float32}(y)</span>

<span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">eachindex</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c"># 70:30 split in training and testing</span>
<span class="c"># shuffle or straight split</span>
<span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">partition</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="w"> </span><span class="mf">0.7</span><span class="p">,</span><span class="w"> </span><span class="n">shuffle</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span>
<span class="n">X_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="p">]</span>
<span class="n">y_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="p">]</span>
<span class="n">X_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="p">]</span>
<span class="n">y_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="p">]</span>

<span class="k">function</span><span class="w"> </span><span class="n">draw_results</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="w"> </span><span class="n">X_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">,</span><span class="w"> </span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="p">)</span>
<span class="w">    </span><span class="n">y_pred_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="sc">&#39;)&#39;</span>

<span class="w">    </span><span class="n">plt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">scatter</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">,</span><span class="w"> </span><span class="n">title</span><span class="o">=</span><span class="s">&quot;Non-linear model of &quot;</span><span class="o">*</span><span class="n">topredict</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;data train&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="n">scatter!</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_train</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;prediction train&quot;</span><span class="p">)</span>

<span class="w">    </span><span class="n">y_pred_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">(</span><span class="n">X_test</span><span class="sc">&#39;)&#39;</span>

<span class="w">    </span><span class="n">scatter!</span><span class="p">(</span><span class="n">test</span><span class="p">,</span><span class="w"> </span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;data test&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="n">scatter!</span><span class="p">(</span><span class="n">test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_test</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;prediction test&quot;</span><span class="p">)</span>

<span class="w">    </span><span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>

<span class="w">    </span><span class="n">rmse_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sqrt</span><span class="p">(</span><span class="n">Flux</span><span class="o">.</span><span class="n">Losses</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_train</span><span class="p">))</span>
<span class="w">    </span><span class="n">rmse_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sqrt</span><span class="p">(</span><span class="n">Flux</span><span class="o">.</span><span class="n">Losses</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_test</span><span class="p">))</span>

<span class="w">    </span><span class="n">println</span><span class="p">(</span><span class="n">topredict</span><span class="p">)</span>
<span class="w">    </span><span class="n">println</span><span class="p">(</span><span class="s">&quot;rmse train: &quot;</span><span class="p">,</span><span class="w"> </span><span class="n">rmse_train</span><span class="p">)</span>
<span class="w">    </span><span class="n">println</span><span class="p">(</span><span class="s">&quot;rmse_test: &quot;</span><span class="p">,</span><span class="w"> </span><span class="n">rmse_test</span><span class="p">)</span>
<span class="k">end</span>

<span class="n">init</span><span class="o">=</span><span class="n">Flux</span><span class="o">.</span><span class="n">glorot_uniform</span><span class="p">()</span>
<span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Flux</span><span class="o">.</span><span class="n">Chain</span><span class="p">(</span>
<span class="w">            </span><span class="n">Flux</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="n">tanh</span><span class="p">,</span><span class="w"> </span><span class="n">init</span><span class="o">=</span><span class="n">init</span><span class="p">,</span><span class="w"> </span><span class="n">bias</span><span class="o">=</span><span class="nb">true</span><span class="p">),</span>
<span class="w">            </span><span class="c"># Flux.Dense(10, 10, tanh, init=init, bias=true),</span>
<span class="w">            </span><span class="c"># Flux.Dropout(0.04),</span>
<span class="w">            </span><span class="n">Flux</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">init</span><span class="o">=</span><span class="n">init</span><span class="p">,</span><span class="w"> </span><span class="n">bias</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">tX</span><span class="p">,</span><span class="w"> </span><span class="n">ty</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Flux</span><span class="o">.</span><span class="n">Losses</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">tX</span><span class="o">&#39;</span><span class="p">),</span><span class="w"> </span><span class="n">ty</span><span class="o">&#39;</span><span class="p">)</span>

<span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[(</span><span class="n">X_train</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">)]</span>

<span class="n">opt_state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Flux</span><span class="o">.</span><span class="n">setup</span><span class="p">(</span><span class="n">Flux</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.01</span><span class="p">),</span><span class="w"> </span><span class="n">model</span><span class="p">)</span><span class="w"> </span><span class="c"># learning rate 0.01</span>

<span class="n">train_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[]</span>
<span class="n">test_loss</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[]</span>
<span class="n">n_epochs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1000</span>

<span class="c"># to animate training</span>
<span class="c"># replace the rest of the code from here with snippet below</span>

<span class="k">for</span><span class="w"> </span><span class="n">epoch</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="n">n_epochs</span>
<span class="w">    </span><span class="n">train!</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">opt_state</span><span class="p">)</span>
<span class="w">    </span><span class="n">ltrain</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sqrt</span><span class="p">(</span><span class="n">loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">X_train</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">))</span>
<span class="w">    </span><span class="n">ltest</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sqrt</span><span class="p">(</span><span class="n">loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">X_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_test</span><span class="p">))</span>
<span class="w">    </span><span class="n">push!</span><span class="p">(</span><span class="n">train_loss</span><span class="p">,</span><span class="w"> </span><span class="n">ltrain</span><span class="p">)</span>
<span class="w">    </span><span class="n">push!</span><span class="p">(</span><span class="n">test_loss</span><span class="p">,</span><span class="w"> </span><span class="n">ltest</span><span class="p">)</span>
<span class="w">    </span><span class="n">println</span><span class="p">(</span><span class="s">&quot;Epoch: </span><span class="si">$epoch</span><span class="s">, rmse train/test: &quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ltrain</span><span class="p">,</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ltest</span><span class="p">)</span>
<span class="k">end</span>

<span class="n">draw_results</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="w"> </span><span class="n">X_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">,</span><span class="w"> </span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="p">)</span>

<span class="n">plt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">plot</span><span class="p">(</span><span class="n">train_loss</span><span class="p">,</span><span class="w"> </span><span class="n">title</span><span class="o">=</span><span class="s">&quot;Losses (root mean square error)&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;training&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">xlabel</span><span class="o">=</span><span class="s">&quot;epochs&quot;</span><span class="p">)</span>
<span class="n">plot!</span><span class="p">(</span><span class="n">test_loss</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;test&quot;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-center" id="id21">
<img alt="../_images/climate_nonlinear_reg.png" src="../_images/climate_nonlinear_reg.png" />
<figcaption>
<p><span class="caption-text">Data points and predictions.</span><a class="headerlink" href="#id21" title="Link to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-center" id="id22">
<img alt="../_images/climate_reg_losses.png" src="../_images/climate_reg_losses.png" />
<figcaption>
<p><span class="caption-text">The losses during training.</span><a class="headerlink" href="#id22" title="Link to this image">#</a></p>
</figcaption>
</figure>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Epoch: 997, rmse train/test: 2.321958298905668 2.8623720534428925
Epoch: 998, rmse train/test: 2.3217000741076217 2.862347448996424
Epoch: 999, rmse train/test: 2.321443844030064 2.8623211237184116
Epoch: 1000, rmse train/test: 2.3211893059494684 2.8622934109353464
mean temp
rmse train: 2.3211893059494684
rmse_test: 2.8622934109353464
</pre></div>
</div>
<p>It is interesting to animate the predictions during the training of the neural network. This will also give us a quick look at animation in Julia.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># instead of the training loop above</span>
<span class="c"># do this to save an animation as a gif</span>

<span class="n">anim</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nd">@animate</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">epoch</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="n">n_epochs</span>

<span class="w">    </span><span class="n">train!</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">opt_state</span><span class="p">)</span>
<span class="w">    </span><span class="n">ltrain</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sqrt</span><span class="p">(</span><span class="n">loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">X_train</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">))</span>
<span class="w">    </span><span class="n">ltest</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sqrt</span><span class="p">(</span><span class="n">loss</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">X_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_test</span><span class="p">))</span>
<span class="w">    </span><span class="n">push!</span><span class="p">(</span><span class="n">train_loss</span><span class="p">,</span><span class="w"> </span><span class="n">ltrain</span><span class="p">)</span>
<span class="w">    </span><span class="n">push!</span><span class="p">(</span><span class="n">test_loss</span><span class="p">,</span><span class="w"> </span><span class="n">ltest</span><span class="p">)</span>
<span class="w">    </span><span class="n">println</span><span class="p">(</span><span class="s">&quot;Epoch: </span><span class="si">$epoch</span><span class="s">, rmse train/test: &quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ltrain</span><span class="p">,</span><span class="w"> </span><span class="s">&quot; &quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ltest</span><span class="p">)</span>

<span class="w">    </span><span class="n">y_pred_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="sc">&#39;)&#39;</span>
<span class="w">    </span><span class="n">y_pred_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">(</span><span class="n">X_test</span><span class="sc">&#39;)&#39;</span>

<span class="w">    </span><span class="n">scatter</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">,</span><span class="w"> </span><span class="n">title</span><span class="o">=</span><span class="s">&quot;Non-linear model of &quot;</span><span class="o">*</span><span class="n">topredict</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;data train&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">yrange</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">40</span><span class="p">])</span>
<span class="w">    </span><span class="n">scatter!</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_train</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;prediction train&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="n">scatter!</span><span class="p">(</span><span class="n">test</span><span class="p">,</span><span class="w"> </span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;data test&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="n">scatter!</span><span class="p">(</span><span class="n">test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_test</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;prediction test&quot;</span><span class="p">)</span>

<span class="k">end</span><span class="w"> </span><span class="n">every</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="c"># include every second frame</span>

<span class="n">gif</span><span class="p">(</span><span class="n">anim</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;anim_points_training.gif&quot;</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-center" id="id23">
<img alt="../_images/anim_points_training.gif" src="../_images/anim_points_training.gif" />
<figcaption>
<p><span class="caption-text">Evolution of prediction during training.</span><a class="headerlink" href="#id23" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Let us also check how well a linear model is doing in this case. It turns out it is doing almost as good as the non-linear model, and perhaps better at capturing the peaks.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">DataFrames</span><span class="p">,</span><span class="w"> </span><span class="n">CSV</span><span class="p">,</span><span class="w"> </span><span class="n">Plots</span><span class="p">,</span><span class="w"> </span><span class="n">Statistics</span><span class="p">,</span><span class="w"> </span><span class="n">Dates</span><span class="p">,</span><span class="w"> </span><span class="n">GLM</span><span class="p">,</span><span class="w"> </span><span class="n">Flux</span><span class="p">,</span><span class="w"> </span><span class="n">StatsBase</span>
<span class="k">using</span><span class="w"> </span><span class="n">MLJ</span><span class="o">:</span><span class="w"> </span><span class="n">shuffle</span><span class="p">,</span><span class="w"> </span><span class="n">partition</span>
<span class="k">using</span><span class="w"> </span><span class="n">Flux</span><span class="o">:</span><span class="w"> </span><span class="n">train!</span>

<span class="c"># data_path = &quot;C:/Users/davidek/julia_kurser/2025-02/DailyDelhiClimateTrain.csv&quot;</span>
<span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CSV</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span><span class="w"> </span><span class="n">DataFrame</span><span class="p">)</span>

<span class="c"># clean up data</span>
<span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">filter</span><span class="p">(</span><span class="ss">:meanpressure</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="mi">950</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">1050</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="p">)</span>

<span class="n">topredict</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;mean temp&quot;</span>
<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="o">.</span><span class="n">meantemp</span>
<span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">df</span><span class="o">.</span><span class="n">humidity</span><span class="w"> </span><span class="n">df</span><span class="o">.</span><span class="n">wind_speed</span><span class="w"> </span><span class="n">df</span><span class="o">.</span><span class="n">meanpressure</span><span class="p">]</span>
<span class="c"># X = [(df.humidity .- 50) (df.wind_speed .- 5) (df.meanpressure .- 1000)]</span>

<span class="n">z</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">eachindex</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c"># 70:30 split in training and testing</span>
<span class="c"># shuffle or straight split</span>
<span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">partition</span><span class="p">(</span><span class="n">z</span><span class="p">,</span><span class="w"> </span><span class="mf">0.7</span><span class="p">,</span><span class="w"> </span><span class="n">shuffle</span><span class="o">=</span><span class="nb">false</span><span class="p">)</span>
<span class="n">X_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="p">]</span>
<span class="n">y_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="p">]</span>
<span class="n">X_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="p">]</span>
<span class="n">y_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">,</span><span class="w"> </span><span class="o">:</span><span class="p">]</span>

<span class="n">df_model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cX1</span><span class="o">=</span><span class="n">X_train</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="w"> </span><span class="n">cX2</span><span class="o">=</span><span class="n">X_train</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="n">cX3</span><span class="o">=</span><span class="n">X_train</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="n">cy</span><span class="o">=</span><span class="n">y_train</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>

<span class="n">model_lin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="nd">@formula</span><span class="p">(</span><span class="n">cy</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="mi">1</span><span class="o">+</span><span class="n">cX1</span><span class="o">+</span><span class="n">cX2</span><span class="o">+</span><span class="n">cX3</span><span class="p">),</span><span class="w"> </span><span class="n">df_model</span><span class="p">)</span>

<span class="k">function</span><span class="w"> </span><span class="n">draw_results_lin</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="w"> </span><span class="n">X_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">,</span><span class="w"> </span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="p">)</span>
<span class="w">    </span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_lin</span>

<span class="w">    </span><span class="n">Z_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">ones</span><span class="p">(</span><span class="n">size</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span><span class="w"> </span><span class="n">X_train</span><span class="p">]</span>

<span class="w">    </span><span class="n">y_pred_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GLM</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">Z_train</span><span class="p">)</span>
<span class="w">    </span><span class="c"># y_train = y_train[:,1]</span>

<span class="w">    </span><span class="n">plt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">scatter</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">,</span><span class="w"> </span><span class="n">title</span><span class="o">=</span><span class="s">&quot;Linear model of &quot;</span><span class="o">*</span><span class="n">topredict</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;data train&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="n">scatter!</span><span class="p">(</span><span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_train</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;prediction train&quot;</span><span class="p">)</span>

<span class="w">    </span><span class="n">Z_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">ones</span><span class="p">(</span><span class="n">size</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span><span class="w"> </span><span class="n">X_test</span><span class="p">]</span>

<span class="w">    </span><span class="n">y_pred_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GLM</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">Z_test</span><span class="p">)</span>
<span class="w">    </span><span class="c"># y_test = y_test[:,1]</span>

<span class="w">    </span><span class="n">scatter!</span><span class="p">(</span><span class="n">test</span><span class="p">,</span><span class="w"> </span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;data test&quot;</span><span class="p">)</span>
<span class="w">    </span><span class="n">scatter!</span><span class="p">(</span><span class="n">test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_test</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;prediction test&quot;</span><span class="p">)</span>

<span class="w">    </span><span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>

<span class="w">    </span><span class="n">rmse_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sqrt</span><span class="p">(</span><span class="n">Flux</span><span class="o">.</span><span class="n">Losses</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_train</span><span class="p">))</span>
<span class="w">    </span><span class="n">rmse_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sqrt</span><span class="p">(</span><span class="n">Flux</span><span class="o">.</span><span class="n">Losses</span><span class="o">.</span><span class="n">mse</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred_test</span><span class="p">))</span>

<span class="w">    </span><span class="n">println</span><span class="p">(</span><span class="n">topredict</span><span class="p">)</span>
<span class="w">    </span><span class="n">println</span><span class="p">(</span><span class="s">&quot;rmse train: &quot;</span><span class="p">,</span><span class="w"> </span><span class="n">rmse_train</span><span class="p">)</span>
<span class="w">    </span><span class="n">println</span><span class="p">(</span><span class="s">&quot;rmse_test: &quot;</span><span class="p">,</span><span class="w"> </span><span class="n">rmse_test</span><span class="p">)</span>
<span class="k">end</span>

<span class="n">draw_results_lin</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="w"> </span><span class="n">X_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">,</span><span class="w"> </span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">model_lin</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>mean temp
rmse train: 2.61686030150272
rmse_test: 3.047019624551555
</pre></div>
</div>
<figure class="align-center" id="id24">
<img alt="../_images/climate_linear_reg.png" src="../_images/climate_linear_reg.png" />
<figcaption>
<p><span class="caption-text">Linear model predictions.</span><a class="headerlink" href="#id24" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="airfoil-data-set">
<h3>Airfoil data set<a class="headerlink" href="#airfoil-data-set" title="Link to this heading">#</a></h3>
<p>Let us now illustrate how to use the package MLJ for non-linear regression. We will use a data set called
<em>Airfoil Self-Noise</em> which may be downloaded from the UC Irvine Machine Learning repository <a class="reference external" href="http://archive.ics.uci.edu/dataset/291/airfoil+self+noise/">here</a>.
This is a data set from NASA created by T. Brooks, D. Pope and M. Marcolini obtained from aerodynamic and acoustic tests of airfoil blade sections.</p>
<p>Below we are downloading the data from Rupak Chakraborty’s gihub account where UC Irvine data has been collected.
The code example below is an adaptation of the <a class="reference external" href="https://juliaai.github.io/DataScienceTutorials.jl/end-to-end/airfoil/">tutorial</a> by Ashrya Agrawal.</p>
<p>The fields of this data set are:</p>
<blockquote>
<div><ul class="simple">
<li><p>frequency (Hz),</p></li>
<li><p>angle of attack (degrees),</p></li>
<li><p>chord length (m),</p></li>
<li><p>free-stream velocity (m/s),</p></li>
<li><p>suction side displacement thickness (m),</p></li>
<li><p>scaled sound pressure level (db).</p></li>
</ul>
</div></blockquote>
<p>We will consider the problem of predicting scaled sound pressure level from the others.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">GLM</span><span class="p">,</span><span class="w"> </span><span class="n">MLJ</span>
<span class="k">import</span><span class="w"> </span><span class="n">MLJDecisionTreeInterface</span>
<span class="k">import</span><span class="w"> </span><span class="n">DataFrames</span>
<span class="k">using</span><span class="w"> </span><span class="n">CSV</span>
<span class="k">using</span><span class="w"> </span><span class="n">HTTP</span>

<span class="n">path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;https://raw.githubusercontent.com/rupakc/UCI-Data-Analysis/master/&quot;</span><span class="o">*</span>
<span class="s">&quot;Airfoil%20Dataset/airfoil_self_noise.dat&quot;</span>

<span class="n">req</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">HTTP</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">path</span><span class="p">);</span>

<span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CSV</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">req</span><span class="o">.</span><span class="n">body</span><span class="p">,</span><span class="w"> </span><span class="n">DataFrames</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">;</span><span class="w"> </span><span class="n">header</span><span class="o">=</span><span class="p">[</span>
<span class="w">                   </span><span class="s">&quot;Frequency&quot;</span><span class="p">,</span><span class="s">&quot;Attack_Angle&quot;</span><span class="p">,</span><span class="s">&quot;Chord_Length&quot;</span><span class="p">,</span>
<span class="w">                   </span><span class="s">&quot;Free_Velocity&quot;</span><span class="p">,</span><span class="s">&quot;Suction_Side&quot;</span><span class="p">,</span><span class="s">&quot;Scaled_Sound&quot;</span>
<span class="w">                   </span><span class="p">]</span>
<span class="w">              </span><span class="p">);</span>
<span class="n">y_column</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">:Scaled_Sound</span>
<span class="n">X_columns</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="o">:</span><span class="mi">5</span>

<span class="n">formula_lin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nd">@formula</span><span class="p">(</span><span class="n">Scaled_Sound</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Frequency</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Attack_Angle</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Chord_Length</span><span class="w"> </span><span class="o">+</span>
<span class="n">Free_Velocity</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Suction_Side</span><span class="p">)</span>

<span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">partition</span><span class="p">(</span><span class="mi">1</span><span class="o">:</span><span class="n">size</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">),</span><span class="w"> </span><span class="mf">0.7</span><span class="p">,</span><span class="w"> </span><span class="n">shuffle</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span>
<span class="n">df_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="n">train</span><span class="p">,</span><span class="o">:</span><span class="p">]</span>
<span class="n">df_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="n">test</span><span class="p">,</span><span class="o">:</span><span class="p">]</span>

<span class="n">model_lin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GLM</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">LinearModel</span><span class="p">,</span><span class="w"> </span><span class="n">formula_lin</span><span class="p">,</span><span class="w"> </span><span class="n">df_train</span><span class="p">)</span>

<span class="n">X_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">Matrix</span><span class="p">(</span><span class="n">df_test</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="w"> </span><span class="n">X_columns</span><span class="p">])</span>
<span class="n">y_test_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">GLM</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">model_lin</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="n">ones</span><span class="p">(</span><span class="n">size</span><span class="p">(</span><span class="n">df_test</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">))</span><span class="w"> </span><span class="n">X_test</span><span class="p">])</span>

<span class="n">y_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_test</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="w"> </span><span class="n">y_column</span><span class="p">]</span>
<span class="n">rmse_lin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rms</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_test_pred</span><span class="p">)</span>

<span class="c"># non-linear model</span>

<span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="w"> </span><span class="n">X_columns</span><span class="p">]</span>
<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="n">y_column</span><span class="p">]</span>
<span class="c"># X = MLJ.transform(MLJ.fit!(machine(Standardizer(), X)), X)</span>
<span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">partition</span><span class="p">(</span><span class="n">eachindex</span><span class="p">(</span><span class="n">y</span><span class="p">),</span><span class="w"> </span><span class="mf">0.7</span><span class="p">,</span><span class="w"> </span><span class="n">shuffle</span><span class="o">=</span><span class="nb">true</span><span class="p">)</span>

<span class="n">model_class</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nd">@load</span><span class="w"> </span><span class="n">DecisionTreeRegressor</span><span class="w"> </span><span class="n">pkg</span><span class="o">=</span><span class="n">DecisionTree</span>
<span class="c"># model_class = @load RandomForestRegressor pkg=DecisionTree</span>

<span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_class</span><span class="p">()</span>
<span class="n">mach</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">machine</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">)</span>
<span class="n">MLJ</span><span class="o">.</span><span class="n">fit!</span><span class="p">(</span><span class="n">mach</span><span class="p">,</span><span class="w"> </span><span class="n">rows</span><span class="o">=</span><span class="n">train</span><span class="p">)</span>
<span class="n">pred_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MLJ</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">mach</span><span class="p">,</span><span class="w"> </span><span class="n">rows</span><span class="o">=</span><span class="n">test</span><span class="p">)</span>

<span class="n">rmse_nlin</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rms</span><span class="p">(</span><span class="n">pred_test</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">])</span>

<span class="c"># Non-linear model is significantly better than linear model.</span>
<span class="n">println</span><span class="p">()</span>
<span class="n">println</span><span class="p">(</span><span class="s">&quot;rmse linear </span><span class="si">$rmse_lin</span><span class="s">&quot;</span><span class="p">)</span>
<span class="n">println</span><span class="p">(</span><span class="s">&quot;rmse non-linear </span><span class="si">$rmse_nlin</span><span class="s">&quot;</span><span class="p">)</span>
<span class="n">println</span><span class="p">()</span>

<span class="c"># get more model suggestions by changing type of frequency</span>
<span class="c"># coerce!(X, :Frequency=&gt;Continuous)</span>

<span class="c"># get model suggestions</span>
<span class="c"># for model in models(matching(X, y))</span>
<span class="c">#     print(&quot;Model Name: &quot; , model.name , &quot; , Package: &quot; , model.package_name , &quot;\n&quot;)</span>
<span class="c"># end</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>rmse linear 5.003216839003985
rmse non-linear 2.9503907573431922
</pre></div>
</div>
</section>
<section id="simple-regression-example">
<h3>Simple regression example<a class="headerlink" href="#simple-regression-example" title="Link to this heading">#</a></h3>
<p>To illustrate more usages of MLJ and various regression models consider the following simple example.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">MLJ</span><span class="p">,</span><span class="w"> </span><span class="n">DataFrames</span>
<span class="k">import</span><span class="w"> </span><span class="n">MLJDecisionTreeInterface</span>
<span class="k">import</span><span class="w"> </span><span class="n">MLJScikitLearnInterface</span>
<span class="k">using</span><span class="w"> </span><span class="n">Plots</span>

<span class="n">Npoints</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">200</span>
<span class="n">noise_level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.1</span>
<span class="n">train_frac</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.7</span>

<span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">range</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="o">=</span><span class="n">Npoints</span><span class="p">)</span>
<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cos</span><span class="o">.</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="n">cos</span><span class="o">.</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="mf">0.01</span><span class="o">*</span><span class="n">X</span><span class="o">.^</span><span class="mi">3</span>
<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="n">noise_level</span><span class="o">*</span><span class="n">randn</span><span class="p">(</span><span class="n">Npoints</span><span class="p">,)</span>

<span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cX</span><span class="o">=</span><span class="n">X</span><span class="p">)</span>

<span class="n">train</span><span class="p">,</span><span class="w"> </span><span class="n">test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MLJ</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="n">eachindex</span><span class="p">(</span><span class="n">y</span><span class="p">),</span><span class="w"> </span><span class="n">train_frac</span><span class="p">,</span><span class="w"> </span><span class="n">shuffle</span><span class="o">=</span><span class="nb">true</span><span class="p">);</span>

<span class="c"># model_class = @load DecisionTreeRegressor pkg=DecisionTree</span>
<span class="c"># model_class = @load RandomForestRegressor pkg=DecisionTree</span>
<span class="n">model_class</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nd">@load</span><span class="w"> </span><span class="n">GaussianProcessRegressor</span><span class="w"> </span><span class="n">pkg</span><span class="o">=</span><span class="n">MLJScikitLearnInterface</span>

<span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model_class</span><span class="p">()</span>
<span class="n">mach</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">machine</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="w"> </span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">)</span>
<span class="n">MLJ</span><span class="o">.</span><span class="n">fit!</span><span class="p">(</span><span class="n">mach</span><span class="p">,</span><span class="w"> </span><span class="n">rows</span><span class="o">=</span><span class="n">train</span><span class="p">)</span>

<span class="n">pred_all</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MLJ</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">mach</span><span class="p">)</span>

<span class="n">pred_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MLJ</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">mach</span><span class="p">,</span><span class="w"> </span><span class="n">rows</span><span class="o">=</span><span class="n">train</span><span class="p">)</span>
<span class="c"># prediction error train</span>
<span class="n">err_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rms</span><span class="p">(</span><span class="n">pred_train</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>

<span class="n">pred_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MLJ</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">mach</span><span class="p">,</span><span class="w"> </span><span class="n">rows</span><span class="o">=</span><span class="n">test</span><span class="p">)</span>
<span class="c"># prediction error test</span>
<span class="n">err_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">rms</span><span class="p">(</span><span class="n">pred_test</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">])</span>

<span class="n">plt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">cX</span><span class="p">,</span><span class="w"> </span><span class="n">pred_all</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;prediction&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">title</span><span class="o">=</span><span class="s">&quot;Simple regression test&quot;</span><span class="p">)</span>
<span class="n">scatter!</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">cX</span><span class="p">[</span><span class="n">train</span><span class="p">],</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">],</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;train&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">markersize</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">scatter!</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">cX</span><span class="p">[</span><span class="n">test</span><span class="p">],</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">],</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;test&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">markersize</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>


<span class="c"># print models that can be used to model the data</span>
<span class="c"># for model in models(matching(X, y))</span>
<span class="c">#     print(&quot;Model Name: &quot; , model.name , &quot; , Package: &quot; , model.package_name , &quot;\n&quot;)</span>
<span class="c"># end</span>

<span class="c"># print root mean square errors of predictions</span>
<span class="n">println</span><span class="p">()</span>
<span class="n">println</span><span class="p">(</span><span class="s">&quot;rmse non-linear train </span><span class="si">$err_train</span><span class="s">&quot;</span><span class="p">)</span>
<span class="n">println</span><span class="p">(</span><span class="s">&quot;rmse non-linear test </span><span class="si">$err_test</span><span class="s">&quot;</span><span class="p">)</span>
<span class="n">println</span><span class="p">()</span>

<span class="c"># expect output something like</span>
<span class="c"># rmse non-linear train 0.086</span>
<span class="c"># rmse non-linear test 0.1311</span>
</pre></div>
</div>
<figure class="align-center">
<img alt="../_images/simple_regression_test.png" src="../_images/simple_regression_test.png" />
</figure>
</section>
</section>
<section id="id6">
<h2>Exercises<a class="headerlink" href="#id6" title="Link to this heading">#</a></h2>
<div class="admonition-todo admonition" id="id7">
<p class="admonition-title">Todo</p>
<p>In the exercises below we use some packages which may be intalled as follows
if needed.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Pkg</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;DataFrames&quot;</span><span class="p">)</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;MLJ&quot;</span><span class="p">)</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;MLJDecisionTreeInterface&quot;</span><span class="p">)</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;MLJScikitLearnInterface&quot;</span><span class="p">)</span>
<span class="n">Pkg</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;Plots&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition-todo admonition" id="id8">
<p class="admonition-title">Todo</p>
<p>Simple regression 1</p>
<p>Run the code in the <a class="reference internal" href="#simple-regression-example">Simple regression example</a> above and see what prediction errors you get.
Look through the code and think about what the various steps do.</p>
</div>
<div class="admonition-todo admonition" id="id9">
<p class="admonition-title">Todo</p>
<p>Simple regression 2a</p>
<p>In the <a class="reference internal" href="#simple-regression-example">Simple regression example</a>, experiment with the settings to change the sampling frequency,
level of noise imposed on the data and fraction of the data that is used for training
(the rest is used for testing).</p>
<div class="admonition-change-parameters solution important dropdown admonition" id="solution-4">
<p class="admonition-title">Change parameters</p>
<p>You can change the following parameters.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">Npoints</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">200</span>
<span class="n">noise_level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.1</span>
<span class="n">train_frac</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.7</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition-todo admonition" id="id10">
<p class="admonition-title">Todo</p>
<p>Simple regression 2b</p>
<p>In the <a class="reference internal" href="#simple-regression-example">Simple regression example</a>, reset the settings:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="n">Npoints</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">200</span>
<span class="n">noise_level</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.1</span>
<span class="n">train_frac</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.7</span>
</pre></div>
</div>
<ul class="simple">
<li><p>What happens to the errors and the prediction (blue curve in the plot) when you decrease the training fraction to 0.3, 0.2 or 0.1?</p></li>
<li><p>Now what happens if you increase the number of points?</p></li>
<li><p>Can you explain the results?</p></li>
</ul>
<div class="admonition-change-noise solution important dropdown admonition" id="solution-5">
<p class="admonition-title">Change noise</p>
<p>It seems like the prediction gets really bad when the training fraction is below 0.2 but if we add more points
we have enough training data to get a good predicition.</p>
</div>
</div>
<div class="admonition-todo admonition" id="id11">
<p class="admonition-title">Todo</p>
<p>Simple regression 3</p>
<p>In the <a class="reference internal" href="#simple-regression-example">Simple regression example</a>, make your own synthetic data set and try it out in the script. The performance will depend a lot on the data and the model.</p>
<div class="admonition-change-function solution important dropdown admonition" id="solution-6">
<p class="admonition-title">Change function</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># replace</span>
<span class="c"># y = cos.(X) .+ cos.(2*X) .+ 0.01*X.^3</span>

<span class="c"># with your own function, for example</span>
<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cos</span><span class="o">.</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="n">sin</span><span class="o">.</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">X</span><span class="p">)</span><span class="o">.^</span><span class="mi">2</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="mf">0.01</span><span class="o">*</span><span class="n">X</span><span class="o">.^</span><span class="mi">3</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition-todo admonition" id="id12">
<p class="admonition-title">Todo</p>
<p>Simple regression 4</p>
<p>Try some other models to train on the data from the <a class="reference internal" href="#simple-regression-example">Simple regression example</a>.
To see a list of available models one can outcomment the following lines.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># print models that can be used to model the data</span>
<span class="k">for</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">models</span><span class="p">(</span><span class="n">matching</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">))</span>
<span class="w">    </span><span class="n">print</span><span class="p">(</span><span class="s">&quot;Model Name: &quot;</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="s">&quot; , Package: &quot;</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="o">.</span><span class="n">package_name</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">)</span>
<span class="k">end</span>
</pre></div>
</div>
<div class="admonition-change-model-class solution important dropdown admonition" id="solution-7">
<p class="admonition-title">Change model class</p>
<p>You can change the model class to one of the models in the previous list.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># replace the model_class</span>
<span class="c"># model_class = @load GaussianProcessRegressor pkg=MLJScikitLearnInterface</span>
<span class="c"># with for exmple random forest</span>
<span class="n">model_class</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nd">@load</span><span class="w"> </span><span class="n">RandomForestRegressor</span><span class="w"> </span><span class="n">pkg</span><span class="o">=</span><span class="n">DecisionTree</span>

<span class="c"># or a decision tree</span>
<span class="c"># model_class = @load DecisionTreeRegressor pkg=DecisionTree</span>
</pre></div>
</div>
<p>For some models you may have to install the package mentioned and
an MLJ interface (MLJDecisionTreeInterface, MLJScikitLearnInterface or similar).</p>
<p>The list of models from above will be something like:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Model Name: ARDRegressor , Package: MLJScikitLearnInterface
Model Name: AdaBoostRegressor , Package: MLJScikitLearnInterface
Model Name: BaggingRegressor , Package: MLJScikitLearnInterface
Model Name: BayesianRidgeRegressor , Package: MLJScikitLearnInterface
Model Name: CatBoostRegressor , Package: CatBoost
Model Name: ConstantRegressor , Package: MLJModels
Model Name: DecisionTreeRegressor , Package: BetaML
Model Name: DecisionTreeRegressor , Package: DecisionTree
Model Name: DeterministicConstantRegressor , Package: MLJModels
Model Name: DummyRegressor , Package: MLJScikitLearnInterface
Model Name: ElasticNetCVRegressor , Package: MLJScikitLearnInterface
Model Name: ElasticNetRegressor , Package: MLJLinearModels
Model Name: ElasticNetRegressor , Package: MLJScikitLearnInterface
Model Name: EpsilonSVR , Package: LIBSVM
Model Name: EvoLinearRegressor , Package: EvoLinear
Model Name: EvoSplineRegressor , Package: EvoLinear
Model Name: EvoTreeGaussian , Package: EvoTrees
Model Name: EvoTreeMLE , Package: EvoTrees
Model Name: EvoTreeRegressor , Package: EvoTrees
Model Name: ExtraTreesRegressor , Package: MLJScikitLearnInterface
Model Name: GaussianMixtureRegressor , Package: BetaML
Model Name: GaussianProcessRegressor , Package: MLJScikitLearnInterface
Model Name: GradientBoostingRegressor , Package: MLJScikitLearnInterface
Model Name: HistGradientBoostingRegressor , Package: MLJScikitLearnInterface
Model Name: HuberRegressor , Package: MLJLinearModels
Model Name: HuberRegressor , Package: MLJScikitLearnInterface
Model Name: KNNRegressor , Package: NearestNeighborModels
Model Name: KNeighborsRegressor , Package: MLJScikitLearnInterface
Model Name: KPLSRegressor , Package: PartialLeastSquaresRegressor
Model Name: LADRegressor , Package: MLJLinearModels
Model Name: LGBMRegressor , Package: LightGBM
Model Name: LarsCVRegressor , Package: MLJScikitLearnInterface
Model Name: LarsRegressor , Package: MLJScikitLearnInterface
Model Name: LassoCVRegressor , Package: MLJScikitLearnInterface
Model Name: LassoLarsCVRegressor , Package: MLJScikitLearnInterface
Model Name: LassoLarsICRegressor , Package: MLJScikitLearnInterface
Model Name: LassoLarsRegressor , Package: MLJScikitLearnInterface
Model Name: LassoRegressor , Package: MLJLinearModels
Model Name: LassoRegressor , Package: MLJScikitLearnInterface
Model Name: LinearRegressor , Package: GLM
Model Name: LinearRegressor , Package: MLJLinearModels
Model Name: LinearRegressor , Package: MLJScikitLearnInterface
Model Name: LinearRegressor , Package: MultivariateStats
Model Name: NeuralNetworkRegressor , Package: BetaML
Model Name: NeuralNetworkRegressor , Package: MLJFlux
Model Name: NuSVR , Package: LIBSVM
Model Name: OrthogonalMatchingPursuitCVRegressor , Package: MLJScikitLearnInterface
Model Name: OrthogonalMatchingPursuitRegressor , Package: MLJScikitLearnInterface
Model Name: PLSRegressor , Package: PartialLeastSquaresRegressor
Model Name: PartLS , Package: PartitionedLS
Model Name: PartLS , Package: PartitionedLS
Model Name: PassiveAggressiveRegressor , Package: MLJScikitLearnInterface
Model Name: QuantileRegressor , Package: MLJLinearModels
Model Name: RANSACRegressor , Package: MLJScikitLearnInterface
Model Name: QuantileRegressor , Package: MLJLinearModels
Model Name: RANSACRegressor , Package: MLJScikitLearnInterface
Model Name: RANSACRegressor , Package: MLJScikitLearnInterface
Model Name: RandomForestRegressor , Package: BetaML
Model Name: RandomForestRegressor , Package: DecisionTree
Model Name: RandomForestRegressor , Package: DecisionTree
Model Name: RandomForestRegressor , Package: MLJScikitLearnInterface
Model Name: RandomForestRegressor , Package: MLJScikitLearnInterface
Model Name: RidgeCVRegressor , Package: MLJScikitLearnInterface
Model Name: RidgeCVRegressor , Package: MLJScikitLearnInterface
Model Name: RidgeRegressor , Package: MLJLinearModels
Model Name: RidgeRegressor , Package: MLJScikitLearnInterface
Model Name: RidgeRegressor , Package: MultivariateStats
Model Name: RobustRegressor , Package: MLJLinearModels
Model Name: SGDRegressor , Package: MLJScikitLearnInterface
Model Name: SRRegressor , Package: SymbolicRegression
Model Name: SVMLinearRegressor , Package: MLJScikitLearnInterface
Model Name: SVMNuRegressor , Package: MLJScikitLearnInterface
Model Name: SVMRegressor , Package: MLJScikitLearnInterface
Model Name: StableForestRegressor , Package: SIRUS
Model Name: RidgeRegressor , Package: MLJLinearModels
Model Name: RidgeRegressor , Package: MLJScikitLearnInterface
Model Name: RidgeRegressor , Package: MultivariateStats
Model Name: RobustRegressor , Package: MLJLinearModels
Model Name: SGDRegressor , Package: MLJScikitLearnInterface
Model Name: SRRegressor , Package: SymbolicRegression
Model Name: SVMLinearRegressor , Package: MLJScikitLearnInterface
Model Name: SVMNuRegressor , Package: MLJScikitLearnInterface
Model Name: SVMRegressor , Package: MLJScikitLearnInterface
Model Name: StableForestRegressor , Package: SIRUS
Model Name: SGDRegressor , Package: MLJScikitLearnInterface
Model Name: SRRegressor , Package: SymbolicRegression
Model Name: SVMLinearRegressor , Package: MLJScikitLearnInterface
Model Name: SVMNuRegressor , Package: MLJScikitLearnInterface
Model Name: SVMRegressor , Package: MLJScikitLearnInterface
Model Name: StableForestRegressor , Package: SIRUS
Model Name: SRRegressor , Package: SymbolicRegression
Model Name: SVMLinearRegressor , Package: MLJScikitLearnInterface
Model Name: SVMNuRegressor , Package: MLJScikitLearnInterface
Model Name: SVMRegressor , Package: MLJScikitLearnInterface
Model Name: StableForestRegressor , Package: SIRUS
Model Name: SVMLinearRegressor , Package: MLJScikitLearnInterface
Model Name: SVMNuRegressor , Package: MLJScikitLearnInterface
Model Name: SVMRegressor , Package: MLJScikitLearnInterface
Model Name: StableForestRegressor , Package: SIRUS
Model Name: SVMNuRegressor , Package: MLJScikitLearnInterface
Model Name: SVMRegressor , Package: MLJScikitLearnInterface
Model Name: StableForestRegressor , Package: SIRUS
Model Name: SVMRegressor , Package: MLJScikitLearnInterface
Model Name: StableForestRegressor , Package: SIRUS
Model Name: StableForestRegressor , Package: SIRUS
Model Name: StableRulesRegressor , Package: SIRUS
Model Name: TheilSenRegressor , Package: MLJScikitLearnInterface
Model Name: XGBoostRegressor , Package: XGBoost
</pre></div>
</div>
</div>
</div>
<div class="admonition-todo admonition" id="id13">
<p class="admonition-title">Todo</p>
<p>Simple regression 5</p>
<p>In the <a class="reference internal" href="#simple-regression-example">Simple regression example</a>, try the
<a class="reference external" href="https://en.wikipedia.org/wiki/Decision_tree_learning">decision tree</a> model:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># replace the model_class</span>
<span class="c"># model_class = @load GaussianProcessRegressor pkg=ScikitLearn</span>
<span class="c"># with for exmple random forest</span>
<span class="n">model_class</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nd">@load</span><span class="w"> </span><span class="n">DecisionTreeRegressor</span><span class="w"> </span><span class="n">pkg</span><span class="o">=</span><span class="n">DecisionTree</span>
</pre></div>
</div>
<p>Note the locally constant (step wise) behavior of the prediction.
What happens to the prediction curve if you increase the number of data points?</p>
<p>When you increase the number of points the prediction curve may be hard see because
of all the plotted points and you can comment out the lines plotting the points:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># scatter!(X.cX[train], y[train], label=&quot;train&quot;, markersize=3)</span>
<span class="c"># scatter!(X.cX[test], y[test], label=&quot;test&quot;, markersize=3)</span>
</pre></div>
</div>
</div>
<div class="admonition-todo admonition" id="id14">
<p class="admonition-title">Todo</p>
<p>Air foil continued</p>
<p>Return to the <a class="reference internal" href="#airfoil-data-set">Airfoil data set</a> example above and run the code for it.
To run the airfoil example you need the packages GLM, MLJ,
MLJDecisionTreeInterface, DataFrames, CSV and HTTP.</p>
<p>Try some different models to model the data. You can list available models as follows at the end of the script.
For some models you may have to install the package mentioned and an MLJ interface
(MLJDecisionTreeInterface, MLJScikitLearnInterface or similar).</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">for</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">models</span><span class="p">(</span><span class="n">matching</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">))</span>
<span class="w">    </span><span class="n">print</span><span class="p">(</span><span class="s">&quot;Model Name: &quot;</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="s">&quot; , Package: &quot;</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="o">.</span><span class="n">package_name</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">)</span>
<span class="k">end</span>

<span class="c"># get more model suggestions by changing type of the Frequency field from Int64 to Float64</span>
<span class="n">coerce!</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="ss">:Frequency</span><span class="o">=&gt;</span><span class="n">Continuous</span><span class="p">)</span>

<span class="k">for</span><span class="w"> </span><span class="n">model</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">models</span><span class="p">(</span><span class="n">matching</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">))</span>
<span class="w">    </span><span class="n">print</span><span class="p">(</span><span class="s">&quot;Model Name: &quot;</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="o">.</span><span class="n">name</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="s">&quot; , Package: &quot;</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="n">model</span><span class="o">.</span><span class="n">package_name</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">)</span>
<span class="k">end</span>
</pre></div>
</div>
</div>
</section>
<section id="some-fourier-based-models-extra-material">
<h2>Some Fourier based models (extra material)<a class="headerlink" href="#some-fourier-based-models-extra-material" title="Link to this heading">#</a></h2>
<p>In the exercises above you fitted trigometric basis functions to data using a linear model.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Plots</span><span class="p">,</span><span class="w"> </span><span class="n">GLM</span><span class="p">,</span><span class="w"> </span><span class="n">DataFrames</span>

<span class="c"># try a cosine combination</span>
<span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">range</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="n">length</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cos</span><span class="o">.</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="n">cos</span><span class="o">.</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">X</span><span class="p">)</span>
<span class="n">y_noisy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="mf">0.1</span><span class="o">*</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,)</span>

<span class="n">plt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;waveform&quot;</span><span class="p">)</span>
<span class="n">plot!</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y_noisy</span><span class="p">,</span><span class="w"> </span><span class="n">seriestype</span><span class="o">=</span><span class="ss">:scatter</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;data&quot;</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>

<span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">y_noisy</span><span class="p">)</span>

<span class="n">lm1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="nd">@formula</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cos</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cos</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cos</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">cos</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="n">X</span><span class="p">)),</span><span class="w"> </span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}, Vector{Int64}}}}, Matrix{Float64}}

y ~ 1 + :(cos(X)) + :(cos(2X)) + :(cos(3X)) + :(cos(4X))

Coefficients:
────────────────────────────────────────────────────────────────────────────
                  Coef.  Std. Error      t  Pr(&gt;|t|)    Lower 95%  Upper 95%
────────────────────────────────────────────────────────────────────────────
(Intercept)   0.0130408   0.0108222   1.21    0.2312  -0.00844393  0.0345256
cos(X)        0.981561    0.015653   62.71    &lt;1e-78   0.950486    1.01264
cos(2X)       0.984984    0.0156219  63.05    &lt;1e-78   0.953971    1.016
cos(3X)      -0.0135547   0.015573   -0.87    0.3863  -0.044471    0.0173616
cos(4X)       0.0148532   0.0155105   0.96    0.3407  -0.015939    0.0456454
────────────────────────────────────────────────────────────────────────────
</pre></div>
</div>
<figure class="align-center" id="id25">
<img alt="../_images/linear_basis_2.png" src="../_images/linear_basis_2.png" />
<figcaption>
<p><span class="caption-text">Fitting trigonomtric functions to data.</span><a class="headerlink" href="#id25" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Note the similarity to Fourier analysis. Let’s see how you do the Fourier transform of data using the package FFTW.
We will use data (waveform) similar to that of the last example.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">Plots</span><span class="p">,</span><span class="w"> </span><span class="n">GLM</span><span class="p">,</span><span class="w"> </span><span class="n">DataFrames</span><span class="p">,</span><span class="w"> </span><span class="n">FFTW</span>

<span class="n">L</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">100</span>
<span class="n">Fs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">100</span>
<span class="n">T</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="o">/</span><span class="n">Fs</span>

<span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">0</span><span class="o">:</span><span class="n">L</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">T</span><span class="p">;</span>
<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cos</span><span class="o">.</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="nb">pi</span><span class="o">*</span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="n">cos</span><span class="o">.</span><span class="p">(</span><span class="mi">5</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="nb">pi</span><span class="o">*</span><span class="n">X</span><span class="p">)</span>
<span class="n">y_noisy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="mf">0.1</span><span class="o">*</span><span class="n">randn</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>

<span class="n">plt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;waveform&quot;</span><span class="p">)</span>
<span class="n">plot!</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y_noisy</span><span class="p">,</span><span class="w"> </span><span class="n">seriestype</span><span class="o">=</span><span class="ss">:scatter</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;data&quot;</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>

<span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X1</span><span class="o">=</span><span class="n">cos</span><span class="o">.</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="nb">pi</span><span class="o">*</span><span class="n">X</span><span class="p">),</span><span class="w"> </span><span class="n">X2</span><span class="o">=</span><span class="n">cos</span><span class="o">.</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="nb">pi</span><span class="o">*</span><span class="n">X</span><span class="p">),</span><span class="w"> </span><span class="n">X3</span><span class="o">=</span><span class="n">cos</span><span class="o">.</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="nb">pi</span><span class="o">*</span><span class="n">X</span><span class="p">),</span><span class="w"> </span><span class="n">X4</span><span class="o">=</span><span class="n">cos</span><span class="o">.</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="nb">pi</span><span class="o">*</span><span class="n">X</span><span class="p">),</span><span class="w">  </span><span class="n">X5</span><span class="o">=</span><span class="n">cos</span><span class="o">.</span><span class="p">(</span><span class="mi">5</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="nb">pi</span><span class="o">*</span><span class="n">X</span><span class="p">),</span><span class="w">  </span><span class="n">X6</span><span class="o">=</span><span class="n">cos</span><span class="o">.</span><span class="p">(</span><span class="mi">6</span><span class="o">*</span><span class="mi">2</span><span class="o">*</span><span class="nb">pi</span><span class="o">*</span><span class="n">X</span><span class="p">),</span><span class="w"> </span><span class="n">y</span><span class="o">=</span><span class="n">y_noisy</span><span class="p">)</span>

<span class="n">lm1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">lm</span><span class="p">(</span><span class="nd">@formula</span><span class="p">(</span><span class="n">y</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">X1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">X2</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">X3</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">X4</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">X5</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">X6</span><span class="p">),</span><span class="w"> </span><span class="n">df</span><span class="p">)</span>

<span class="n">print</span><span class="p">(</span><span class="n">lm1</span><span class="p">)</span>

<span class="c"># use function fft (Fast Fourier Transform)</span>
<span class="n">y_fft</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fft</span><span class="p">(</span><span class="n">y_noisy</span><span class="p">)</span>

<span class="c"># some housekeeping</span>
<span class="n">P2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">abs</span><span class="o">.</span><span class="p">(</span><span class="n">y_fft</span><span class="o">/</span><span class="n">L</span><span class="p">)</span>
<span class="n">P1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">P2</span><span class="p">[</span><span class="mi">1</span><span class="o">:</span><span class="kt">Int</span><span class="p">(</span><span class="n">L</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
<span class="n">P1</span><span class="p">[</span><span class="mi">2</span><span class="o">:</span><span class="k">end</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="o">*</span><span class="n">P1</span><span class="p">[</span><span class="mi">2</span><span class="o">:</span><span class="k">end</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">f</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">Fs</span><span class="o">/</span><span class="n">L</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">0</span><span class="o">:</span><span class="kt">Int</span><span class="p">(</span><span class="n">L</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>

<span class="n">plt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="n">P1</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;freqs&quot;</span><span class="p">)</span>
<span class="c"># zooming in a bit on the frequency graph</span>
<span class="c"># plt = plot(f, P1, label=&quot;freqs&quot;, xlims=(0,10), xticks = 0:10)</span>

<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>StatsModels.TableRegressionModel{LinearModel{GLM.LmResp{Vector{Float64}}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}, Vector{Int64}}}}, Matrix{Float64}}

y ~ 1 + X1 + X2 + X3 + X4 + X5 + X6

Coefficients:
──────────────────────────────────────────────────────────────────────────────
                   Coef.  Std. Error      t  Pr(&gt;|t|)   Lower 95%    Upper 95%
──────────────────────────────────────────────────────────────────────────────
(Intercept)   0.00221541   0.0102879   0.22    0.8300  -0.0182143   0.0226451
X1            0.999929     0.0145493  68.73    &lt;1e-80   0.971037    1.02882
X2           -0.00803306   0.0145493  -0.55    0.5822  -0.036925    0.0208589
X3           -0.0319954    0.0145493  -2.20    0.0304  -0.0608874  -0.00310339
X4           -0.0288931    0.0145493  -1.99    0.0500  -0.0577851  -1.16669e-6
X5            1.01005      0.0145493  69.42    &lt;1e-81   0.981157    1.03894
X6            0.00464845   0.0145493   0.32    0.7501  -0.0242435   0.0335404
──────────────────────────────────────────────────────────────────────────────
</pre></div>
</div>
<figure class="align-center" id="id26">
<img alt="../_images/linear_basis_3.png" src="../_images/linear_basis_3.png" />
<figcaption>
<p><span class="caption-text">A combination of cosines with noise.</span><a class="headerlink" href="#id26" title="Link to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-center" id="id27">
<img alt="../_images/linear_freqs.png" src="../_images/linear_freqs.png" />
<figcaption>
<p><span class="caption-text">The Fourier coeffients from FFT, the frequencies are 1 and 5.</span><a class="headerlink" href="#id27" title="Link to this image">#</a></p>
</figcaption>
</figure>
<figure class="align-center" id="id28">
<img alt="../_images/linear_freqs_zoomed.png" src="../_images/linear_freqs_zoomed.png" />
<figcaption>
<p><span class="caption-text">Zooming in a bit on the frequency graph.</span><a class="headerlink" href="#id28" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Since the climate data explored above is periodic we may attempt a simple model based on Fourier transforms. To have a cleaner presentaiton we aggregate the data over each month.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">DataFrames</span><span class="p">,</span><span class="w"> </span><span class="n">CSV</span><span class="p">,</span><span class="w"> </span><span class="n">DataFrames</span><span class="p">,</span><span class="w"> </span><span class="n">Plots</span><span class="p">,</span><span class="w"> </span><span class="n">Statistics</span><span class="p">,</span><span class="w"> </span><span class="n">Dates</span><span class="p">,</span><span class="w"> </span><span class="n">GLM</span><span class="p">,</span><span class="w"> </span><span class="n">StatsBase</span>

<span class="c"># data_path = &quot;C:/Users/davidek/julia_kurser/2025-02/DailyDelhiClimateTrain.csv&quot;</span>
<span class="n">df_train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">CSV</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span><span class="w"> </span><span class="n">DataFrame</span><span class="p">)</span>

<span class="c"># clean up data</span>
<span class="n">df_train</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="ss">:meanpressure</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="mi">1000</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">50</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">df_train</span><span class="o">.</span><span class="n">meanpressure</span><span class="p">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">df_train</span><span class="o">.</span><span class="n">meanpressure</span><span class="p">]</span>

<span class="c"># add year and month fields</span>
<span class="n">df_train</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="ss">:year</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">Float64</span><span class="o">.</span><span class="p">(</span><span class="n">year</span><span class="o">.</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="ss">:date</span><span class="p">]))</span>
<span class="n">df_train</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="ss">:month</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kt">Float64</span><span class="o">.</span><span class="p">(</span><span class="n">month</span><span class="o">.</span><span class="p">(</span><span class="n">df_train</span><span class="p">[</span><span class="o">:</span><span class="p">,</span><span class="ss">:date</span><span class="p">]))</span>

<span class="n">df_train_m</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">combine</span><span class="p">(</span><span class="n">groupby</span><span class="p">(</span><span class="n">df_train</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="ss">:year</span><span class="p">,</span><span class="w"> </span><span class="ss">:month</span><span class="p">]),</span><span class="w"> </span><span class="ss">:meantemp</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">mean</span><span class="p">,</span><span class="w"> </span><span class="ss">:humidity</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">mean</span><span class="p">,</span>
<span class="ss">:wind_speed</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">mean</span><span class="p">,</span><span class="w"> </span><span class="ss">:meanpressure</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">mean</span><span class="p">)</span>

<span class="n">M_m</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">df_train_m</span><span class="o">.</span><span class="n">meantemp_mean</span><span class="w"> </span><span class="n">df_train_m</span><span class="o">.</span><span class="n">humidity_mean</span><span class="w"> </span><span class="n">df_train_m</span><span class="o">.</span><span class="n">wind_speed_mean</span><span class="w"> </span><span class="n">df_train_m</span><span class="o">.</span><span class="n">meanpressure_mean</span><span class="p">]</span>

<span class="n">plottitles</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s">&quot;meantemp&quot;</span><span class="w"> </span><span class="s">&quot;humidity&quot;</span><span class="w"> </span><span class="s">&quot;wind_speed&quot;</span><span class="w"> </span><span class="s">&quot;meanpressure&quot;</span><span class="p">]</span>
<span class="n">plotylabels</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="p">[</span><span class="s">&quot;C°&quot;</span><span class="w"> </span><span class="s">&quot;g/m^3?&quot;</span><span class="w"> </span><span class="s">&quot;km/h?&quot;</span><span class="w"> </span><span class="s">&quot;hPa&quot;</span><span class="p">]</span>
<span class="n">plt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">scatter</span><span class="p">(</span><span class="n">M_m</span><span class="p">,</span><span class="w"> </span><span class="n">layout</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="w"> </span><span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="w"> </span><span class="mi">2</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="mi">4</span><span class="p">],</span><span class="w"> </span><span class="n">legend</span><span class="o">=</span><span class="nb">false</span><span class="p">,</span><span class="w"> </span><span class="n">title</span><span class="o">=</span><span class="n">plottitles</span><span class="p">,</span><span class="w"> </span><span class="n">xlabel</span><span class="o">=</span><span class="s">&quot;time (months)&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylabel</span><span class="o">=</span><span class="n">plotylabels</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">800</span><span class="p">,</span><span class="mi">800</span><span class="p">))</span>

<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-center" id="id29">
<img alt="../_images/climate_plots_months.png" src="../_images/climate_plots_months.png" />
<figcaption>
<p><span class="caption-text">Aggregated data, mean value for each month.</span><a class="headerlink" href="#id29" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Now, the Fourier transform gives us the frequency components of the signals. Let us take the mean temperature as an example.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">FFTW</span>

<span class="c"># just to have even number of samples for simplicity</span>
<span class="n">df_train_m</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_train_m</span><span class="p">[</span><span class="mi">2</span><span class="o">:</span><span class="k">end</span><span class="p">,</span><span class="o">:</span><span class="p">]</span>

<span class="c"># normalize for better exposition of frequencies</span>
<span class="n">the_mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mean</span><span class="p">(</span><span class="n">df_train_m</span><span class="o">.</span><span class="n">meantemp_mean</span><span class="p">)</span>
<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df_train_m</span><span class="o">.</span><span class="n">meantemp_mean</span><span class="w"> </span><span class="o">.-</span><span class="w"> </span><span class="n">the_mean</span>

<span class="n">L</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">size</span><span class="p">(</span><span class="n">df_train_m</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">Fs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span>
<span class="n">T</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="o">/</span><span class="n">Fs</span>

<span class="n">y_fft</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fft</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">P2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">abs</span><span class="o">.</span><span class="p">(</span><span class="n">y_fft</span><span class="o">/</span><span class="n">L</span><span class="p">)</span>
<span class="n">P1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">P2</span><span class="p">[</span><span class="mi">1</span><span class="o">:</span><span class="kt">Int</span><span class="p">(</span><span class="n">L</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
<span class="n">P1</span><span class="p">[</span><span class="mi">2</span><span class="o">:</span><span class="k">end</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span><span class="o">*</span><span class="n">P1</span><span class="p">[</span><span class="mi">2</span><span class="o">:</span><span class="k">end</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="n">f</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">Fs</span><span class="o">/</span><span class="n">L</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="mi">0</span><span class="o">:</span><span class="kt">Int</span><span class="p">(</span><span class="n">L</span><span class="o">/</span><span class="mi">2</span><span class="p">))</span>

<span class="n">plt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">plot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span><span class="w"> </span><span class="n">P1</span><span class="p">,</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="s">&quot;freqs&quot;</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-center" id="id30">
<img alt="../_images/climate_fft.png" src="../_images/climate_fft.png" />
<figcaption>
<p><span class="caption-text">Plots of frequency content of temperature data. There is a peak at roughly 1/12 corresonding to a period of 1 year.</span><a class="headerlink" href="#id30" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>We use the frequency information for interpolation and extrapolation and thereby build a model of the data.
To decrease overfitting, we may project to a lower dimensional subspace of basis functions (essentially trigonmetric functions) by setting a limit parameter proj_lim below.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># up sample function to finer grid (interpolation)</span>
<span class="n">upsample</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">2</span>
<span class="n">L_u</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">(</span><span class="kt">Int64</span><span class="p">,</span><span class="w"> </span><span class="n">L</span><span class="o">*</span><span class="n">upsample</span><span class="p">)</span>
<span class="n">t_u</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">0</span><span class="o">:</span><span class="n">L_u</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">L</span><span class="o">/</span><span class="n">L_u</span>

<span class="c"># set limit for projection</span>
<span class="c"># proj_lim 0 means no projection</span>
<span class="k">function</span><span class="w"> </span><span class="n">get_model</span><span class="p">(</span><span class="n">proj_lim</span><span class="p">)</span>

<span class="w">  </span><span class="n">y_fft_tmp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y_fft</span><span class="o">.*</span><span class="p">[</span><span class="w"> </span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">proj_lim</span><span class="o">*</span><span class="n">L</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="mf">0.0</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="mf">1.0</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">y_fft</span><span class="p">]</span>

<span class="w">  </span><span class="c"># center frequencies on constant component (zero frequency)</span>
<span class="w">  </span><span class="n">y_fft_shift</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fftshift</span><span class="p">(</span><span class="n">y_fft_tmp</span><span class="p">)</span>

<span class="w">  </span><span class="c"># fill in zeros (padding) for higher frequencies for upsampling</span>
<span class="w">  </span><span class="n">npad</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">floor</span><span class="p">(</span><span class="kt">Int64</span><span class="p">,</span><span class="w"> </span><span class="n">L_u</span><span class="o">/</span><span class="mi">2</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">L</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>

<span class="w">  </span><span class="n">y_fft_pad</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">zeros</span><span class="p">(</span><span class="n">npad</span><span class="p">);</span><span class="w"> </span><span class="n">y_fft_shift</span><span class="p">;</span><span class="w"> </span><span class="n">zeros</span><span class="p">(</span><span class="n">npad</span><span class="p">)]</span>

<span class="w">  </span><span class="c"># up sampling by applying inverse Fourier transform to paddded frequency vector</span>
<span class="w">  </span><span class="c"># same as interpolating using linear combination of trignometric functions</span>
<span class="w">  </span><span class="n">pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">real</span><span class="p">(</span><span class="n">ifft</span><span class="p">(</span><span class="n">fftshift</span><span class="p">(</span><span class="n">y_fft_pad</span><span class="p">)))</span><span class="o">*</span><span class="n">L_u</span><span class="o">/</span><span class="n">L</span>

<span class="w">  </span><span class="c"># ifft(fftshift(y_fft_pad))</span>

<span class="w">  </span><span class="n">pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pred</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="n">the_mean</span>

<span class="k">end</span>

<span class="n">pred0</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_model</span><span class="p">(</span><span class="mf">0.0</span><span class="p">)</span>
<span class="n">pred1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_model</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="n">pred2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_model</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>

<span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">.+</span><span class="w"> </span><span class="n">the_mean</span>

<span class="n">t</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">0</span><span class="o">:</span><span class="n">L</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">scatter</span><span class="p">([</span><span class="n">t</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="n">t</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="n">y</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="n">y</span><span class="p">],</span><span class="w"> </span><span class="n">layout</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="p">[</span><span class="s">&quot;data&quot;</span><span class="w"> </span><span class="s">&quot;data&quot;</span><span class="w"> </span><span class="s">&quot;data&quot;</span><span class="p">])</span>
<span class="n">plot!</span><span class="p">([</span><span class="n">t_u</span><span class="w"> </span><span class="n">t_u</span><span class="w"> </span><span class="n">t_u</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="n">pred2</span><span class="w"> </span><span class="n">pred1</span><span class="w"> </span><span class="n">pred0</span><span class="p">],</span><span class="w"> </span><span class="n">layout</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span><span class="w"> </span><span class="n">label</span><span class="o">=</span><span class="p">[</span><span class="s">&quot;model crude&quot;</span><span class="w"> </span><span class="s">&quot;model fine&quot;</span><span class="w"> </span><span class="s">&quot;model overfit&quot;</span><span class="p">],</span><span class="w"> </span><span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="s">&quot;meantemp crude (limit 2)&quot;</span><span class="w"> </span><span class="s">&quot;meantemp fine (limit 1)&quot;</span><span class="w"> </span><span class="s">&quot;meantemp overfit (limit 0)&quot;</span><span class="p">],</span><span class="w"> </span><span class="n">xlabel</span><span class="o">=</span><span class="s">&quot;time (months)&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">ylabel</span><span class="o">=</span><span class="s">&quot;C°&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">800</span><span class="p">,</span><span class="mi">800</span><span class="p">))</span>

<span class="n">display</span><span class="p">(</span><span class="n">plt</span><span class="p">)</span>
</pre></div>
</div>
<figure class="align-center" id="id31">
<img alt="../_images/climate_fft_model.png" src="../_images/climate_fft_model.png" />
<figcaption>
<p><span class="caption-text">Three models of varying crudeness and overfit.</span><a class="headerlink" href="#id31" title="Link to this image">#</a></p>
</figcaption>
</figure>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../data-science/"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Data science and machine learning</p>
      </div>
    </a>
    <a class="right-next"
       href="../guide/"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Instructor’s guide</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-with-synthetic-data">Linear regression with synthetic data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-models-with-basis-functions">Linear models with basis functions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fitting-a-polynomial-to-data">Fitting a polynomial to data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">Exercises</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-data">Loading data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#non-linear-regression">Non-linear regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#climate-data">Climate data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#airfoil-data-set">Airfoil data set</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-regression-example">Simple regression example</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">Exercises</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#some-fourier-based-models-extra-material">Some Fourier based models (extra material)</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Kjartan Thor Wikfeldt, Anastasiia Andriievska, David Eklund
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023, EuroCC National Competence Center Sweden at RISE Research Institutes of Sweden.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>